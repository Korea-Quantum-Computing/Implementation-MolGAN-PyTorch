{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from rdkit import RDLogger\n",
    "from args import get_GAN_config\n",
    "from util_dir.utils_io import get_date_postfix\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Remove flooding logs.\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "import rdkit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.backends import cudnn\n",
    "\n",
    "\n",
    "from pysmiles import read_smiles\n",
    "from layers import GraphConvolution, GraphAggregation, MultiGraphConvolutionLayers, MultiDenseLayer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# TqdmWarning: IProgress not found. Please update jupyter and ipywidgets.\n",
    "# pip install ipywidgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "config = get_GAN_config()\n",
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(z_dim=8, g_conv_dim=[128, 256, 512], d_conv_dim=[[128, 64], 128, [128, 64]], lambda_cls=1, lambda_rec=10, lambda_gp=10.0, post_method='softmax', batch_size=32, num_epochs=150, g_lr=0.0001, d_lr=0.0001, dropout=0.0, n_critic=5, resume_epoch=None, test_epochs=100, num_workers=1, mode='train', mol_data_dir='data/qm9_5k.sparsedataset', saving_dir='../exp_results/GAN/', log_step=1, sample_step=1000, model_save_step=1, lr_update_step=1000, lambda_wgan=0.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.saving_dir = os.path.join(config.saving_dir, get_date_postfix())\n",
    "config.log_dir_path = os.path.join(config.saving_dir, 'log_dir')\n",
    "config.model_dir_path = os.path.join(config.saving_dir, 'model_dir')\n",
    "config.img_dir_path = os.path.join(config.saving_dir, 'img_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if not exist.\n",
    "if not os.path.exists(config.log_dir_path):\n",
    "    os.makedirs(config.log_dir_path)\n",
    "if not os.path.exists(config.model_dir_path):\n",
    "    os.makedirs(config.model_dir_path)\n",
    "if not os.path.exists(config.img_dir_path):\n",
    "    os.makedirs(config.img_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_name = os.path.join(config.log_dir_path, get_date_postfix() + '_logger.log')\n",
    "logging.basicConfig(filename=log_p_name, level=logging.INFO)\n",
    "logging.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.mol_data_dir = '../data/qm9_5k.sparsedataset'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.sparse_molecular_dataset import SparseMolecularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SparseMolecularDataset()\n",
    "data.load(config.mol_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Model configurations.\n",
    "z_dim = config.z_dim\n",
    "m_dim = data.atom_num_types\n",
    "b_dim = data.bond_num_types\n",
    "g_conv_dim = config.g_conv_dim\n",
    "d_conv_dim = config.d_conv_dim\n",
    "la = config.lambda_wgan\n",
    "lambda_rec = config.lambda_rec\n",
    "la_gp = config.lambda_gp\n",
    "post_method = config.post_method\n",
    "metric = 'validity,qed'\n",
    "# Training configurations.\n",
    "batch_size = config.batch_size\n",
    "num_epochs = config.num_epochs\n",
    "num_steps = (len(data) // batch_size)\n",
    "g_lr = config.g_lr\n",
    "d_lr = config.d_lr\n",
    "dropout = config.dropout\n",
    "if  la > 0:\n",
    "    n_critic = config.n_critic\n",
    "else:\n",
    "    n_critic = 1\n",
    "resume_epoch = config.resume_epoch\n",
    "# Training or testing.\n",
    "mode = config.mode\n",
    "\n",
    "# Miscellaneous.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: ', device)\n",
    "# Directories.\n",
    "log_dir_path = config.log_dir_path\n",
    "model_dir_path = config.model_dir_path\n",
    "img_dir_path = config.img_dir_path\n",
    "\n",
    "# Step size.\n",
    "model_save_step = config.model_save_step"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator network.\"\"\"\n",
    "\n",
    "    def __init__(self, conv_dims, z_dim, vertexes, edges, nodes, dropout_rate):\n",
    "        super(Generator, self).__init__()\n",
    "        self.activation_f = torch.nn.Tanh()\n",
    "        self.multi_dense_layer = MultiDenseLayer(z_dim, conv_dims, self.activation_f)\n",
    "\n",
    "        self.vertexes = vertexes\n",
    "        self.edges = edges\n",
    "        self.nodes = nodes\n",
    "\n",
    "        self.edges_layer = nn.Linear(conv_dims[-1], edges * vertexes * vertexes)\n",
    "        self.nodes_layer = nn.Linear(conv_dims[-1], vertexes * nodes)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.multi_dense_layer(x)\n",
    "        edges_logits = self.edges_layer(output).view(-1, self.edges, self.vertexes, self.vertexes)\n",
    "        edges_logits = (edges_logits + edges_logits.permute(0, 1, 3, 2)) / 2\n",
    "        edges_logits = self.dropout(edges_logits.permute(0, 2, 3, 1))\n",
    "\n",
    "        nodes_logits = self.nodes_layer(output)\n",
    "        nodes_logits = self.dropout(nodes_logits.view(-1, self.vertexes, self.nodes))\n",
    "\n",
    "        return edges_logits, nodes_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator network with PatchGAN.\"\"\"\n",
    "\n",
    "    def __init__(self, conv_dim, m_dim, b_dim, with_features=False, f_dim=0, dropout_rate=0.):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.activation_f = torch.nn.Tanh()\n",
    "        graph_conv_dim, aux_dim, linear_dim = conv_dim\n",
    "        # discriminator\n",
    "        self.gcn_layer = GraphConvolution(m_dim, graph_conv_dim, b_dim, with_features, f_dim, dropout_rate)\n",
    "        self.agg_layer = GraphAggregation(graph_conv_dim[-1] + m_dim, aux_dim, self.activation_f, with_features, f_dim,\n",
    "                                          dropout_rate)\n",
    "        self.multi_dense_layer = MultiDenseLayer(aux_dim, linear_dim, self.activation_f, dropout_rate=dropout_rate)\n",
    "\n",
    "        self.output_layer = nn.Linear(linear_dim[-1], 1)\n",
    "\n",
    "    def forward(self, adj, hidden, node, activation=None):\n",
    "        adj = adj[:, :, :, 1:].permute(0, 3, 1, 2)\n",
    "        h_1 = self.gcn_layer(node, adj, hidden)\n",
    "        h = self.agg_layer(h_1, node, hidden)\n",
    "        h = self.multi_dense_layer(h)\n",
    "\n",
    "        output = self.output_layer(h)\n",
    "        output = activation(output) if activation is not None else output\n",
    "\n",
    "        return output, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(g_conv_dim,\n",
    "          z_dim,\n",
    "          data.vertexes,\n",
    "          data.bond_num_types,\n",
    "          data.atom_num_types,\n",
    "          dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator(d_conv_dim, m_dim, b_dim - 1, dropout)\n",
    "V = Discriminator(d_conv_dim, m_dim, b_dim - 1, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_network(model, name, log=None):\n",
    "    \"\"\"Print out the network information.\"\"\"\n",
    "    num_params = 0\n",
    "    for p in model.parameters():\n",
    "        num_params += p.numel()\n",
    "    print(model)\n",
    "    print(name)\n",
    "    print(\"The number of parameters: {}\".format(num_params))\n",
    "    if log is not None:\n",
    "        log.info(model)\n",
    "        log.info(name)\n",
    "        log.info(\"The number of parameters: {}\".format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (activation_f): Tanh()\n",
      "  (multi_dense_layer): MultiDenseLayer(\n",
      "    (linear_layer): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Tanh()\n",
      "      (3): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (4): Dropout(p=0.0, inplace=False)\n",
      "      (5): Tanh()\n",
      "      (6): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (7): Dropout(p=0.0, inplace=False)\n",
      "      (8): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (edges_layer): Linear(in_features=512, out_features=405, bias=True)\n",
      "  (nodes_layer): Linear(in_features=512, out_features=45, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "G\n",
      "The number of parameters: 396610\n",
      "Discriminator(\n",
      "  (activation_f): Tanh()\n",
      "  (gcn_layer): GraphConvolution(\n",
      "    (activation_f): Tanh()\n",
      "    (multi_graph_convolution_layers): MultiGraphConvolutionLayers(\n",
      "      (conv_nets): ModuleList(\n",
      "        (0): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (1): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (2): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (3): Linear(in_features=5, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=5, out_features=128, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (1): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (2): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (3): Linear(in_features=133, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=133, out_features=64, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (agg_layer): GraphAggregation(\n",
      "    (activation): Tanh()\n",
      "    (i): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (j): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (multi_dense_layer): MultiDenseLayer(\n",
      "    (linear_layer): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Tanh()\n",
      "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (4): Dropout(p=0.0, inplace=False)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "D\n",
      "The number of parameters: 89473\n",
      "Discriminator(\n",
      "  (activation_f): Tanh()\n",
      "  (gcn_layer): GraphConvolution(\n",
      "    (activation_f): Tanh()\n",
      "    (multi_graph_convolution_layers): MultiGraphConvolutionLayers(\n",
      "      (conv_nets): ModuleList(\n",
      "        (0): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (1): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (2): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (3): Linear(in_features=5, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=5, out_features=128, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (1): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (2): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (3): Linear(in_features=133, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=133, out_features=64, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (agg_layer): GraphAggregation(\n",
      "    (activation): Tanh()\n",
      "    (i): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (j): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (multi_dense_layer): MultiDenseLayer(\n",
      "    (linear_layer): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Tanh()\n",
      "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (4): Dropout(p=0.0, inplace=False)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "V\n",
      "The number of parameters: 89473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (activation_f): Tanh()\n",
       "  (gcn_layer): GraphConvolution(\n",
       "    (activation_f): Tanh()\n",
       "    (multi_graph_convolution_layers): MultiGraphConvolutionLayers(\n",
       "      (conv_nets): ModuleList(\n",
       "        (0): GraphConvolutionLayer(\n",
       "          (adj_list): ModuleList(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (3): Linear(in_features=5, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear_2): Linear(in_features=5, out_features=128, bias=True)\n",
       "          (activation): Tanh()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GraphConvolutionLayer(\n",
       "          (adj_list): ModuleList(\n",
       "            (0): Linear(in_features=133, out_features=64, bias=True)\n",
       "            (1): Linear(in_features=133, out_features=64, bias=True)\n",
       "            (2): Linear(in_features=133, out_features=64, bias=True)\n",
       "            (3): Linear(in_features=133, out_features=64, bias=True)\n",
       "          )\n",
       "          (linear_2): Linear(in_features=133, out_features=64, bias=True)\n",
       "          (activation): Tanh()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (agg_layer): GraphAggregation(\n",
       "    (activation): Tanh()\n",
       "    (i): Sequential(\n",
       "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (j): Sequential(\n",
       "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (multi_dense_layer): MultiDenseLayer(\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): Dropout(p=0.0, inplace=False)\n",
       "      (2): Tanh()\n",
       "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (4): Dropout(p=0.0, inplace=False)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_optimizer = torch.optim.RMSprop(G.parameters(), g_lr)\n",
    "d_optimizer = torch.optim.RMSprop(D.parameters(), d_lr)\n",
    "v_optimizer = torch.optim.RMSprop(V.parameters(), g_lr)\n",
    "print_network(G, 'G', logging)\n",
    "print_network(D, 'D', logging)\n",
    "print_network(V, 'V', logging)\n",
    "\n",
    "G.to(device)\n",
    "D.to(device)\n",
    "V.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_la = la\n",
    "epoch_i = 0\n",
    "a_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "losses = defaultdict(list)\n",
    "scores = defaultdict(list)\n",
    "the_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, smiles, data_S, data_A, data_X, data_D, data_F, data_Le, data_Lv\n",
    "# a: Adjacent matrix,\n",
    "# x: node \n",
    "mols, _, _, a, x, _, _, _, _ = data.next_train_batch(batch_size) # generator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate single data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### molecular graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fc65d27ee00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mols[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### molecular graph with detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAACWCAIAAADCEh9HAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3dd1hU19YH4N8wQxkQpChdDEJQsRErJYJRYqXE9mHvIdFIYjRKotcoKUaNBVsiGsUSCxZUbMhVEBvGigqKBQtKLyJl6HO+P7Z3QigDzAzMYNb75LmPnrPbeHVx5uy91+ZxHAdCCCGyUlP2AAghpHmjMEoIIXKhMEoIIXKhMEoIIXKhMEoIIXIRKHsABACKinD/PgDY2EBfv+rdV6+Qng5zc5iZ1au1lBSkpgKAtjY6dlToQAkh1dDTqEp4/Bg9e6JnT0yfXsPddevQsye2bKlXUyUlcHd/29q4cYodJiGkBhRGVUtoKI4fl6uFgAA8eIAPPlDQgAghdaEwqkL09aGmBj8/FBbK2MLdu1i1Cqam+PFHhY6MEFI7CqMqxMoK48fjxQsZg2BFBaZNQ1kZAgNreMFKCGkkFEZVy88/Q1sba9YgLq7Bddeswc2bGDQIPj6NMDJCSC0ojKqWNm3g74+yMsyYAbG45jLDh8PBAWfP/uPis2cICIBQiE2bmmCYhJC/URhVOfPno107/PUXtm+vucCDB7hzB7m5f1/hOPj6orAQ338PG5umGSYh5C0KoypH8kTp74+MjBoK/Pordu9G795/X9m+HWfPolMnzJvXRIMkhEhQGFVFgwfD2xs5OVi0qIa7np6YMAFWVm9/m5aG+fOhpoagIKirN+UwCSEAhVGVtX49dHSwfTtu3Kij5OzZeP0aY8bA3h6vX7/9Lz8fACoq8Pq17MunCCH1QWFURVlZYdEiiMX45htIyaydkIDDhwFg714YGv7935AhAHDvHgwNa94ZRQhRFNpTr7rmzcOuXYiORmZmrWWEQoweXcP1rCxERUFfHx9/DEfHxhsjIYTCqArT0EBQEPr1e5u1RCI8HHl5cHaGpSXatsWBAzXUvXwZH36I996r+S4hRIHoS71Kc3XFmDFVL86ZAx8fXL2qjAERQqqhMKrq1qxBy5b/uGJri44doaenpAERQv6JRyeDqgKWb1QohL19DXcTE5Gb24B8owAKCvDwIeUbJaQpUBhVXbGxcHCoV8m8vBoeTk+eRP/+EAoVPi5CyD/Ql3oVdfQoevTAV1/VUezRIzg6wsur6vUzZ+DtDRcXJCU10gAJIW9RGFVF9+9j8mSIxbC0rKOkmRkSEhAdjevX/3Hd2hq2trh9G05OuHat8UZKCKEwqnqys+Hpibw8TJyI+fPrKKyrixkzAGDDhn9ct7PDlSvo3x8pKXBzw+7djTVaQgi9G1UtZWUYOBDnz8PJCVFR0NSsu8qLF7C1BY+Hp0+rPr2Wl2PuXGzYAB4PCxZg2TKo0c9NQhSN/lWpltmzcf48zM1x8GC9YiiAtm0xfDjKyvD771VvCQRYvx5BQRAIsGLF24dcQohi0dOoClm7FnPnQihEdDR69WpAxZgYODvD0BBJSdDRqaHAxYsYORKZmejSBceOwdpaUUMmhNDTqMqIiMCCBeDxEBzcsBgKwMkJjo7Iyan1HWjfvoiJgb097t1Dr144f17u4RJC/ofCqEp4+BA+Pigvx5IlMp6k9PXXALB2ba1Hj9jY4OpVeHoiOxuDBtWaWp8Q0lAURpXv9Wt4eSE3FyNG4PvvZWxk5EhYW+PRI4SH11pGVxdHjmDuXJSWYvp0LF2aXVFRIWN/hJD/oTCqZBUVGD8ejx7BwQG7doHHk7EdPh+zZgHA2rV1FFu9Gnv2oG3biqCgQUOHDs2tfKgTIaThaIpJyfz8sHEjTE1x7RratJGrqbw8tGmDvDzExqJbtzoKX7lyc/jwoRkZGR06dAgLC3v//ffl6puQfzF6GlWm4OCQEycea2nhyBF5YygAPT1MmQIA69bVXdjZucetW7d69OiRkJDQp0+fs1XOayaE1Bs9jSpNdHT0xx9/3KKF7u+/3/fxMVFIm8+e4f33IRDg+XOYmtZdvrCwcNKkSaGhoXw+/+eff/b391fIMAj5V6GnUeV4/vz56NGjy8rKfH0/VVQMBWBtDU9PlJRg8+Z6ldfR0Tl06NDy5cs5jvv22299fX1LS0sVNRhC/iXoaVQJ8vPzXVxc7t27N3jw4BMnTvD5fAU2fuEC3NzQujWSkqClVd9aBw8enDJlikgkcnFxCQ0NNTY2VuCQCHm30dNoUxOLxRMmTLh3717Hjh3379+v2BgKwNUVvXsjMxN79jSg1ujRoy9fvmxlZXX58mUnJ6e4uDjFjoqQdxiF0ab23XffhYWFGRoahoWFtaxyPIiCfPklAKxdK+1k5uocHByuXr3ap0+fp0+fOjk5HT16tDHGRsi7h77UN6ndu3dPmjRJXV39zJkzH330USP1UlaGdu3w6hUiIvDxxw2rW1xcPGPGjD179qipqa1du/ZLFpIBABzHxcTEREZGJicnFxcXW1hYuLu7u7q6qtWeNorjuKioqL/++uvZs2c6Ojo2NjYeHh7vvfeerJ+MEJXEkaZy48YNoVAI4Pfff2/svpYt4wBuyBAZqwcGBqqrq588eVJyJT4+vnfv3tX//jg7Oz979qzGRvLy8gYOHFilvIaGxrp162QcFiEqicJoE0lOTrawsADg5+fXBN3l5HA6OhyPx8XHy9jC8+fPJb9+8OCBoaEhgHbt2v3222+3bt2Kj48/dOjQhx9+CKB3795isbh6C59++ikAGxubqKio4uLi7OzstWvXqqmp8Xi86OhoGYdFiOqhMNoURCJRr169ALi7u5eVlTVNpzNncgDn66uAphwdHVm4zMvLq3xdLBYvWbLk6dOnNdbS1dUFcPz48coXx44dC+Dzzz9XwLAIUQ00xdToOI6bNm3a9evXra2t9+3bJxAImqbfr7+Gmhp270ZWllztXLly5erVq2pqajt37mSRUYLH4y1dutS6pvSl5eXlhYWFAKysrCpfb9euHYA3b97INSZCVAmF0UYXEBCwf/9+PT2948ePt2rVqsn6ff99DBmCoiIEBcnVzpkzZwC4uLh06NBBSrHS0tLk5OTU1FT2W4FAwMLrli1buErTmDExMQD69Okj15gIUSUURhudsbGxpqZmSEhIp06dmrhrloR0wwaUlMjeSGxsLAD2vV6Kq1evWlpa2tvbS67Mnz8fwKZNmwYOHHju3DmxWLxx48bIyMg+ffqw16aEvBua6Atm81JeXn7r1q2kpKSioiIzMzMnJyedGo/mAABUVFSwQFOFpqZm586dAcyaNcvb25vNLzWxAQPg4IDYWISEYNIkGRvJzs4GYGZm1tCKn332WWFh4TfffHP27NmzZ8+amJikp6ePHDlyx44d2traMo6GEBWk7JezqqW4uHjJkiUGBgaV/4iEQuG8efMKCwtrrPLixYsa/2AdHR2bePA1Cg7mAK5LF66mufR6Yeuc1q9fL71YWVlZTk5Obm6u5MrTp0979uzJ4/EmTJggeZjV1NRcvHhxRUWFjKMhRPXQ0+jfRCLRkCFDLly4oKam5uXl5eLiIhQKHz16tH///tWrV8fGxp45c6b63s20tDQA7dq1Gz16dOXrTf8VvkZjx+K773DvHqKj0a+fLC2wrVZ1TgoJBILKP35EItHAgQOfPHkSFBTk6+sL4PHjx3/88cf69et//PHHgoKCNWvWyDIaQlSQsuO4CvHz8wNgYGBw+fLlytczMzM/+uijP//8s8ZaoaGhACZMmNAkY5RFQAAHcF5eMlb//PPPAYwdO7ZBtbZs2QKgR48eVa6HhYUBEAgEWVlZMg6IEBVDU0xvpaenBwUFAdi0aZOzs3PlW61atYqMjBw/fnyNFdnctAyvDpvMzJkQCnH8OBISZKnu4uICICIioqQhE1UsuUn37t2rXPf09NTR0SkvL3/8+LEsoyFE9VAYfSssLKy0tNTS0tKngSdzqn4Ybd0a48eD47BxoyzVhw8f3rJly+zs7FWrVtW/VosWLQA8ffq0yvWsrCy2npRtiyLkHUBh9K3r168DcHNzk5JoA0B8fHyHDh26VTrqiIVRIyOjyMjILVu2/PHHH3/99Vdjj7ah5swBj4fgYGRnN7iujo7OsmXLAHz//fe//PJL5bzOeXl5mzdvfvLkCYBHjx5Nnjx5FjtXD/Dw8AAQGRl54MABSfny8vJvvvkGQJcuXej0J/LuUPZbBVXh5eUF4D//+Y/0YizaampqSq4MHToUQJWpp549ez548KCRh9wwAwdyALdihSx1xWLxggUL2EczMDAYPHjw6NGje/fuzdYtffvttxzHRUdHA9DX15fU+uqrr1gVV1fXOXPmzJw5s3379gD09PRu3LihqM9FiNJRGH1rwIABAJYtWya9WE5OzoEDBw4fPiy5cvz48VGjRq1duzYyMvLKlSvbtm3r2LEjgDZt2qjULMrp0xzAWVhwpaUythAdHf3JJ59I9oPy+Xx7e/sFCxYkJSVxHPf06dN58+YtXry4cpV9+/Y5OTlJ9r+2bNly4sSJtWWEIqSZojD6lre3N4BFixbJ35RIJGIL73/66Sf5W1Ogrl05gNu7V9523rx5k56eXlxcXM/yxcXFr169ysjIkLdjQlQSvRt9y9zcHDVNichAKBSOGjUKAPueqzpmzwaA1avrLpmbm+vj4/Py5csa7+rp6bEdrlJaiIyMvH//Pvu1pqamhYVF69atGzpgQpoFCqNvsb060dHRFRUV8rfGgnJubq78TSnQpEkwMcHNm7h8WVqx8vJyHx+fAwcOsGXzMnj8+PHIkSOdnJxOnTolWwuENCMURt/y8vISCoUpKSl79+6Vv7X4+Hj8Lymc6tDUBEsJsnattGLz5s2LiIgwMTEJkjU3VJs2bTw9PfPy8jw8PJYuXSpbI4Q0G8p+q6BC2GR0y5YtIyMjq9xKTExkr/ays7N37dq1Z88edr2goGDAgAHbtm2rnP49NjaWbaCUZCy+c+dOk3yCuqWnc1paHJ/PPXlSc4Hg4GAA6urqciaoF4vFy5cvZ6vHxo4dKxKJ5GmNEFVGYfRvxcXF7u7uAHg83uDBg1esWLF58+ZFixa5u7urqan9+OOPXLUFT6dOnWLT0N26dVu0aNHq1aunTJmirq4OYOLEiSy2HjlyRE1NzdfXt8ny3ks3eTIHcHPm1HDr0qVL7I3n1q1bFdLXyZMn9fT0ADg5OaWmpiqkTUJUDYXRfygpKfn555+rJ1fu0qXLoUOHOI6Lj493cHDo06ePpMqVK1dcXV15PJ6ksJGR0cqVKyVBc9euXSw2DRo06PXr18r5YJXcvcvxeJyuLlcpGRPHcdzz58+NjY0BzJ8/X6Hd3WVHgVpYWFy/fl2BLROiIuiA5RpUVFTcvn375cuXxcXF+vr6Xbp0sbS0lF4lLS3t7t27BQUF5ubmPXv2rHJSSExMzIgRI9LS0mxtbY8fPy49jXwT6N8fUVFYs+ZtXmcABQUFLi4ud+/eHTRo0MmTJ6snspJHdnb2qFGjzp8/r6WltW3btnHjximwcVJYWJiSkpKenp6Wlpaampqenp6SkpKRkTF79uzBgwcre3T/ChRGm0hycrK3t/fNmzf19PT27t07bNgwJQ7m+HF4eaFtWzx5AoEAYrF4xIgRx44d69ChQ0xMjL6+vsJ7LC0tnTlz5vbt23k83oIFC5YtWyZ90y2p7PXr1ykpKampqSkpKa9fv2a/qPzbGmutXr167ty51a8/f/48KSmptLS0devWnTt3rs+PzIyMjIcPH5aXl7dt21bVJk5VAYXRplNYWDhp0qTQ0FA+n//zzz/7+/srayQcB3t7JCTg4EGMGoWFCxf+8ssvhoaGf/31l62tbeP1u2XLli+++KK8vHzUqFE7d+6kHPhMQUFBcnJyRkZGampqWloae6jMyMhITk5OT0/PyMgQi8VSqguFQlNTUzMzMxMTE3Nzc2NjY3Nzc1NT027durVp00ZSTCwWb926dfXq1ZVza7Vu3XrOnDnz589nL/SrS09Pnz179pEjRyQLAXv27Ll58+YePXoo4qO/IyiMNimO41auXLlw4UKxWDxjxoxNmzZpaGgoZSS//YYvvoCzM+bMOejj48Pn88PDw9mO2EYVERHh4+OTm5vbrVu3Y8eOtW3btrF7VGXJycl2dnYikUhKGR6PZ2xsbGxsbGFhYWxsbGZmZmZmJvmtubk5m8STrry8fNy4cQcPHgTQu3fvvn376ujoPHr06Pjx44WFhZ6enqGhodXPrC0oKHBycoqLi7O0tJwwYYK2tnZYWNiNGzd0dXUvX77cpUsXeT77O0Wpb2b/pQ4cOMAexFxcXNLT05UyhsJCzsiIA25qaWkD+O2335qs60ePHrG3w61atZJzWVVzV1xczOPxtLS0zMzMevTo4eHh4evru2TJksDAwAMHDly8eDExMbFU5iQIlQQEBADQ0tKqnA6C47gXL15079595cqVNdZavHgxAFtbW0l2CPZNAoCrq6v8o3pnUBhVjtu3b7MD3Nu0aXPr1i2ljOGLL1IASwDTp09v4q5zcnLY2jJNTc3g4OAm7l2l5OfnN3YXb968YelfN27cWP1ueXl5jbXKy8tNTEwAsDUqEsnJyewrVHx8fKMMtxmiMKo0KSkp7Lj2Fi1aHDlypIl7LyoqcnDoBYDH4yUmJjZx7xzHlZeXS94Of/nll7X9Y1ZZZWVlqampiYmJOTk59a9VUlLSeEOqzZ49ewAYGRk1qPcbN26wB9iioqIqtz766CMAa9asUegwmzGaLVUaMzOz6OjoyZMnFxQUjBgxYunSpVxTvafmOG769OmxsddbtGjBcdzmzZubpt/K+Hz+8uXLt2zZoqGhsX79eg8PjzpPzVMRt2/f/r//+z8jIyMzMzMbGxtDQ0N7e/sNGzZIycYgFovDwsL69esnFApHjBjRlKMFcO3aNQCurq7SX8S/fPnS1dXV1dW1vLwc/9vQ/N5772lpaVUpyd7JsAIEoHejKiAwMJCt/hkzZkzTbJr88ccfAejq6oaEhADQ19dvgq+Wtbl06RJb9m9nZ5eQkKCsYdTT5s2b2Qqhli1bDhs2bPz48W5ubuzK0KFDqz/uFRcX79y5097eXvIvztnZuYnHzM6srXNXRcL/zupin2LlypWo5R3o999/D8DT07NRhtsM0QHLyvfVV1/Z2dmNHTt2//79Dx8+PHbsWOV1Kgp39OjRJUuWqKmp7d2718PDY8OGDZcuXdqxY8dslkevybm4uMTExHh7e8fFxTk7Ox88eLB///5KGUmdIiMjZ82aJRaL/fz8li9fLlmw9eTJExaqSkpKqjzxnTlzZvLkyXZ2dvPnzzc0NPzuu+8aY2DFxcVpaWls1T1bis/WTq1YsaJjx44FBQUAdHR0pDdiYmKyceNGAGzKvqioCECNi4jZSdrsTC0C0NOoyrh37561tTUAc3Pza9euNVIv8fHxbH3Mr7/+yq4cPnwYgLW1tXLfTubn53/yyScABALB+vXrlTgSKdhBpz4+PtVv5ebm1vgHWFZWdv/+ffbriIgIyPo0KhKJEhMTL168eODAgcDAQH9//4kTJ3p4ePTo0cPMzKzyXuTKWHIcNrfu7+/foB5XrFgBwM3NrfqtJUuWAPDw8JDhg7yT6GlUVXTu3Pn69eujR4+OiopydXXdunXrhAkTFNtFdnY2y183adIkdrQcgE8++cTGxiYxMfHEiRPsCAClaNGiRWhoaEBAwA8//PDll1/GxcVt3LixtjXhShEfH3/r1i0AP/zwQ/W7LKdXdQKBgB0qI11RUVFqaqpk1b3koVKyFL+srExKdU1NTbaG1MTExMzMzNTUlC3F79mzJwA24f78+fN6fMq/scwSmZmZ1W9lZWVJChCAnkZVTFlZGftyzePx/P39KyoqFNVyaWmpm5sbACcnpyrnfwQGBqKW546mt3v3bjanUeVcrEuXLo0fP97S0lJdXV0gEFhZWc2cOVP6sU6HDx8eMGAAy7qvr68/YsSImzdvyjywrVu3ArC1tZVerLCwcMqUKVOmTKmehqbGp9HLly9LjreSwsjIqFOnTgMGDJgwYcLcuXNXr169e/fuc+fOxcXF1Xnk144dOwBYWFg06K9TTEwMgBYtWlRfuDpo0CAAta02/ReiMKqKgoKC2IPYsGHD3rx5o5A2P/30UwDm5ubJyclVbuXl5bGHqcZ7mdAgMTExHh4ektm28vJyPz8/Fk20tbW7d+/eq1cvthBSW1v71KlT1VuoqKiYOnUq+2nUtWtXNzc3Fkw1NTXDw8NlGxVbi17nN9mcnBw21FevXlW5VWMYvXv3LhuYmZmZvb29u7v7xIkT/f39JSvw4+Li5JwAzMzMZD+Z9u/fX/9apaWl7B3omTNnKl/PyclhL4Vv374tz6jeJRRGVVRERAT7S9y1a1f5j9JcvXo1AKFQWFuqunnz5gGYOHGinB01BvYmTiAQrFy5UhJbi4qKVqxYwefza5yA3rZtGwAbGxtJwmyRSMReEVpZWcmW+JWdFz1u3DjpxUQi0dy5c+fOnVv951+NYbSsrKxBK09l8+WXXwJo1apV9aOtc3Jy2INzYWHh6dOnT58+LclBzj5yz549Ky8dZd+WevXq1dhjbkYojKqux48fs9dqrVq1On/+vMztnDlzRiAQ8Hg8KQ8jz58/FwgE6urqL1++lLmjxvDq1Ss2cbxp06bqdyWzN1U8ePBg2rRpd+/erXwxIyODrUy6evVq9Sr5+fkJCQkXLlwICQlZt27dd999N2XKlCFDhnTr1o1toPz2228BjBw5UubPIs8Uk5wKCwudnJwAqKurT5gwYfv27UePHt2wYcP48eOFQuHPP//MVVvwxHFcZmYm22v3wQcfBAUF7d69my161dTUvHLlStN/CpVFYVSlvX79mr2HEgqF1b+M14dIJDIzMwMQEBAgvSRbsrNw4UKZRtpYli1bBsDOzq7yMS0yYwmk2e7G8PDwkSNHuri42NraSs81xV4Crlq1CkDljN0NpcQwynFcYWHhvHnzqq+lNzU13bJlC8dxiYmJ5ubm5ubmlV+GPnz4sFevXpXLm5ubV/maT2imXqXp6+ufPHly3rx5ZmZm7LTRhhIKhceOHdu1axd7tSfF119/ffDgwc2bNy9cuLDONYZN5vLlywC8vLxqW9PD3L17NywszMzMbPr06VKKsRWUbErn1atXbLEXo62tzea4KyedYxPfbCEaW+3EknOzN7PNi7a29qpVqwICAi5duvTixQuRSGRoaNipU6cPPviA7f5o165dcnJylVp2dnbXrl27efNmXFxcWVmZtbW1q6urSq2gUAWUKI/8zcnJ6erVq5s3b/7ss8+UPZa3OnTo8PDhw+Dg4ClTpkgptmPHjqlTp3bv3v3mzZu1lUlISOjYsSOfz8/IyDA0NHz27Nm1a9dYgk4LC4s6I2NxcbGlpWV2dvamTZtmzZolw2f573//O3DgQGdn58vST7iWSWlpaZVlUunp6cnJybt27apPJj0iD3oabTby8/MPHjx44cKFtLQ0AObm5kOHDv3kk0+qp4msrKio6NChQ+fOnUtLS9PQ0LCxsfHx8XF0dKyx8Jw5c8aMGbNmzZpPP/1URbLTs432bLZNCisrK29vb+k5p3/99VcAI0aMMDQ0BGBtbc0eM+tJS0vLz89v6dKlixYtcnR0ZA+nlYlEIm1tbbFYnJiYCKBdu3aKPYuFrS2tLQ1+RkZGjZv6U1JSKIw2NnoabR5CQ0M///zz6muhP/jgg9DQUPbKr7qrV6+OGTPmxYsXlS9qamo+fvy4xv2mFRUV77///rNnz06ePDl06FAFjV0uVlZWL1++PHTo0MiRI+Vp59ixY8OHD9fW1o6NjZU5w39paWn//v0vX76spaX1+eefDxs2zNTUNC0tLTY2Njg4uH///hs2bHj9+jUL069evbKwsABw7do19n/B3bt3f/rpp/bt27OcBoaGhpXzZJeUlFRfe8/iI7tYUlIiZWwCgcDY2FjyRkKS49nd3b22rQFEYZT9cpbU7ejRo+zZcPDgwefOncvOzs7NzY2KimKzT6NHj66x1oMHD9hjyKhRo27evFlWViYSiWJiYg4cOCClL/bI5u7u3jgfpcEcHBxQS6LM+mNL3Pl8fpXUmTIoLCz09fWt/g2Ax+NNnTqVq2ndaG270SRrhv78808WeaXT09Pr0KGDq6vr2LFjv/rqq+XLl+/cuTM8PPzu3btpaWkKmYIjsqGnUVVXWFhobW2dmZk5derUbdu2VZ5pEYvFmzdvnjp1qlAorF7R3d393LlzY8eO3bNnj/T5mcry8vLatGmTl5cXGxvbrVs3xXwGOUyZMmXnzp2TJk3auXOnbC2cP3/ey8ursLAwODh40qRJChnVq1evIiIiEhMTc3NzDQwM2rdv379/f/bsCaC4uBiAZE48Kiqq8vFHEq1btx4+fDiAw4cPszWtBgYGbC5R8r8GBgbsF5aWlvRQqbqUHcdJHf744w8ARkZGeXl59a/16NEjHo8nEAhSUlIa2iNbqj1t2rSGVmwMLOVwy5Ytq++trA+2H0xTU3PHjh0KH5uiiEQiZZ0lQxSCwqiqGzt2LOpxzkdmZuaVK1ckm3ZYxjNHR0cZenz69Cmfz9fU1ExNTZWhumKx+XEAPj4+0nNQVVRUVP5iKxKJJPtfaa04aVQqMRtLpIiLiwPAUvVIcfr0aWdn58mTJ7Pfsp3adnZ2qampP/zww8cff+zs7DxhwoTw8PA6e7S2tvb09CwpKVFKVvwq2GFN6urqISEh/fr1O3HiRGZmpkgkunPnzrp16zp16nTnzh0AO3bs4PP5kj+lhISEPn36bN261dzcPCgoSEND42YlVebcCJGXsuM4qQN741blQMfq9u3bp6OjI9khwzbtOTo6soX0WlpakgVMs2bNqrPT6OhoAK1bt65+Do9ShIeHs2fSKtTU1LZv385xXHBwMIDu3buz8iyXVW2a/gg/8m6jKSZVZ2FhkZKScuTIEZbVuJ4GDRoUERHB4/E+++yz2bNnd+rUqaioaMVfFLgAAA1vSURBVM+ePbNnzy4pKdm/f7+Pj4/0Fnr37n39+vVt27ZNmzZNvk+gGEVFRceOHbtw4UJKSkpFRYWxsbGDg4Onpydb7PXmzZvk5GShUMiWggYFBT179qy2pnr16iXn8ilC/kHZcZzUgWUn2bZtW4NqeXl5Afj666+rXGeZnOqznmn37t0AOnfurJSVNDTlQpoRejeq6tq3bw/g3r17DarFMpOLRKIq1/v16wfgwYMHdbbg4+NjaWkZFxd39uzZBnUtv0OHDtna2oaGhjZxv4TIhsKoqnN1dQVw7NgxsVhc/1qdOnUCUH25IjuLosZ1plWoq6uzneNr166tf7/yu3Xr1uTJk/Pz81NTU5uyX0Jkp+zHYVKHjIwMtpB79erV9a91//59AJqamlXS67EdNTUeylZdTk6Ojo4Oj8erLa2nwqWmprKpJBVZtUpIfVAYbQZYpks1NbXFixdXzql+7949Pz8/tsA+IiKiX79+n376qeQu2yrar18/tvyzrKxszZo1PB5PTU3t4sWL9ex65syZAD777DOFfqCaFRUV9enTB0Dfvn2rH/hOiMqiMNoMiMXihQsXsg2d6urqXbt2dXR0lJzLGBgYyHHcrl27ADg4OEhqPX/+nKUuZ4dTsl3bampqkqOV6+PRo0dqampCoTAzM1PxH6wSsVg8fvx4AO+9915GRkaj9kWIYvGXLl3a1O8RSAPxeLwBAwZ4enqKxeL8/PykpKS0tDR9fX03Nzd/f/+pU6cKBAItLa33339/0KBBnTt3ZrX09fUnT57M4/FycnKSk5NbtGjh7u7++++/s21R9WRkZHT9+vX79++3bNmSvaVtJL/88ktgYKCuru7Zs2cblL+OEKWjdaOkDufOnXN3dzcxMXnx4oWmpmZjdHHs2DG2X+Do0aOenp6N0QUhjYdm6puZrVu3sgRCsnny5MnSpUsbNOk/YMAABweH9PT0kJAQmfuV4v79+5MmTRKLxb/88gvFUNIsKfutAmmAlStXAhgwYIBs1SsqKrp27QrAw8OjQfmi2FbLLl26KHwpflZWlo2NDVT1bGdC6oPCaLMRHh7O5/N5PF5ISIjMjVy6dMnY2BiAnZ1dQkJCPWsVFxebmpoCiIqKkrnr6kpLS9l2gB49ekgOoCek2aEw2jw8ePCAZe396aef5GwqMTGRTUMZGhqeO3eunrUCAgIAeHl5ydl7Zb6+vgDMzc0lieIJaY4ojDYD2dnZ7PigUaNGKeRrdX5+Pkt0IhAI1q9fX58qGRkZQqGQx+PV/xlWOrY5SigUXrt2TSENEqIsFEZVHTtGDUD37t0LCwsV1axYLF6yZAlbi+rr61taWlpnlRkzZgCYPXu2/L1HREQIBAIej7dv3z75WyNEuSiMqjq2j8jMzOzly5cKb3zfvn1sf33fvn3rXPQeFxfH4/G0tbWzsrLk6TQhIUFfXx/AkiVL5GmHEBVBYVSlsbNAtLS0rl692khdxMTEmJmZAbCxsYmPj5deeODAgQBWrFghc3dv3ryxt7cHMGLECDrMkrwbKIyqrgsXLmhoaPB4vD///LNRO0pOTu7VqxcAXV3dsLAwKSVPnz4NwMLCoj4vAaorLy8fOnQoAAcHh4KCAlnHS4hqoTCqop4+fcp2zS9cuLAJuisqKmLJn/h8/vLly2srJhaL2bPk3r17ZejFz88PgImJSVJSkhyDJUS1UBhVRXl5eWxNkre3d0VFRdN0KhaLly9fzo5sGjduXG2nMG3ZsoWt9Gxo+9u3bwegoaERHR0t92AJUSEURlVORUWFh4cHAHt7+8pp8ZrGiRMn9PT0ADg7O6elpVUvUFxcbGJiAuDSpUv1b/bixYsaGhoAtm7dqrjBEqISKIyqHHZckpGR0ZMnT5QygDt37rBz4iwtLW/cuFG9wH/+8x8AI0eOrGeDz549Y1unFixYoNCREqISKIyqlp07dwJQV1dX7LbLhsrMzGRnFOvo6FQ/2zk9PV1LS4vP5ycmJtbZVH5+fpcuXQAMGjSovLy8ccZLiDJRGFUhly9fZpnogoKClD0Wrri4eOrUqQB4PJ6/v3+VV7STJ09GTSePVlFRUcHOKO3QoUNubm5jjpcQpaFEeaoiJSVl9OjRJSUlc+bMYZvNlUtTU3P79u2rVq1SU1MLDw+vkp1vzpw5AoEgLy9PeiNZWVmJiYlGRkYnTpxgOQEIefdQ2maVUFRU5OrqeuPGjY8//vjUqVMCgUDZI/pbeHh4x44d27ZtW+V6WloaS/skXV5e3pMnT7p37944oyNE+SiMKh/HcWPHjg0JCWnfvn1MTIyBgYGyR1Sr0tLS7OzsiooKY2NjNvNep+Li4szMTFNTU3V19cYeHiFKQV/qlW/p0qUhISF6enqhoaGqGUM5jjty5Ej//v11dXXNzc3btGnTokWLgQMHXrhwQUqtP//808HBQSgUWllZaWtrd+7cedu2bfRjm7yDlPpmlnCHDh3i8Xh8Pv/kyZPKHkvNSktL2QYnAJaWll5eXiNGjLCzswPA4/HWrVtXYy32eldPT8/b23vq1Kns5GQ01aYsQpoShVFlunXrlo6ODoDagpEq+O677wBoamoGBwdXTiZy5MgRPT29GrM0HT58GICbm9vr168lF9kuJj6fn5KS0gTDJqTJUBhVmtTU1DZt2gCYMmWKssdSq5SUFPZO848//qh+t7bD60tKStavX5+cnFzlOssScOrUKcUPlBDlUaEZ4X+V4uLi4cOHv3z58sMPP9y8ebOyh1Orffv2lZWVtWvXbtq0adXvsrBYnYaGBstCUll5eXlBQQEAIyMjhY+TECWiKSblCAgIuHr1qrW1dWhoaCMd/q4QMTExAIYOHcry5NcmNjbW19d38eLFUsoEBgYWFxe3b9++R48eCh4lIUpFT6PK4e/v//jx4yVLlrRu3VrZY5HmxYsXADp06CC92LNnz7Zu3Wpra/vjjz9Wvp6amhoVFZWUlBQZGfnf//7Xzs4uLCyMz+c34ogJaXIURuuF47gTJ04cOXIkLi4uOzvbwMCgW7dukyZNYhvPq7h///5XX31VW1M8Hi8iIkJfX//QoUONOWTFePPmDQCW80kKGxsbPz8/ln+kstu3b48fP579ukWLFkuWLGFn8xHyTlH2y9lmID093cXFhf1xqampGRgYSFaSz5gxo3q6jStXrkj5A+fz+Ur5FLLp2rUraplfqo/c3NwbN26Eh4cHBgZaW1sDmDBhgmJHSIjSURitQ1FREQsl5ubme/bsYWdzlpaWHj161NraWigU/vXXX/VsKjg4GIC3t3djjlfBBgwYACAgIED+pnJzc83NzQGo7ApZQmRDU0x1WLNmzd27d/X19S9evDhu3DhtbW0A6urq3t7eFy5cuHjxYu/evevZVGBgIACWTrS5+OCDDwBIf76up5YtW7KToqOiouRvjRDVQWG0DkFBQQD8/f3btWtX5ZalpWX9J50jIiLu3LnTs2fPvn37KniIjWnYsGEAzp07l5iYKH9rbK9BnXmhCGleKIxK8/Tp06SkJABjxoyRXjI8PDwkJOTly5e1FVi9ejWa26MoADc3t169epWXl0+cODE/P7/K3bKyMrFYDEAkEj1//jw5OZldz8rK8vLyevr0aeXCBQUFZ86cAcCyOBPy7lD2WwWVdvLkSQD6+vp1luzYsSOA/fv313j33r17PB7P0tJStnOJlSs+Pt7Q0BBA27ZtAwMDr1+//uDBg1OnTvn7+5uamp4+fZrjuNDQUAC2trasym+//QbAwMBgzZo1sbGxjx49OnHihKOjIwBzc3PK30zeMbTgSZrXr1+jfrtu2Dqe2jITr1q1iuO4r7/+ujkmi7O3t7906dL06dNjYmLmzJlT+ZZQKExNTa1eZebMmWKx+Ntvv507d27l6x07djxw4ADlbybvGMo3Ks2+ffvGjRtnY2Pz5MkTmRtJSUmxtrbW1NR8+fJls44g165dO3/+fHJycllZmbGxcdeuXd3d3dmS0vLy8qKiIjU1Nfb2k8nKygoLC4uLiysoKDA0NPzwww8HDhxYzyylhDQj9DQqjb6+PoCsrCx5Gtm4cWNpaamfn1+zjqEAevfuXduyBIFAoKurW+Viq1atatyJT8g7hp5GpUlKSmKHZyQmJlafqa8PkUhkZWX15s2bxMREKysrRQ+QEKJ8NFMvjZWVFXvpuX//ftla2LZtW3Z29ujRoymGEvKuojBah5kzZwJYsWLF48ePG1q3oqJi3bp1AKrMzBBC3iUURuswe/bsHj165OXl9e3bd9euXYWFhex6UlLS8uXLJTPRQ4YMsbW1PXXqVOW6R44cSUxMdHNzq/9OJ0JIs0PvRuuWnZ09cuTI6OhoABoaGq1bt37z5g3LQNyyZcu0tDQtLS17e/sHDx7s37/fx8dHUtHZ2TkmJubYsWNeXl5KGz0hpJFRGK0XjuNOnjwZGhoaHx+flZXVokULGxsbFxeXsWPHsnQbkZGReXl5vXr1srCwYFVSUlLmzJmjq6u7detWNTV66ifknUVhlBBC5EJPSYQQIhcKo4QQIhcKo4QQIhcKo4QQIhcKo4QQIhcKo4QQIhcKo4QQIhcKo4QQIpf/B6REqBLXZBm1AAABBHpUWHRyZGtpdFBLTCByZGtpdCAyMDIyLjA5LjMAAHice79v7T0GIOBlgABGIOYEYm4gbmBk48gA0kzMjBIMbBwaICaLBFAwAcgCijHBWczsHAoglgQLRIiJSYKVDSzEIsEGEWJklmCHq+fgZmDkYGZkAhrNwMzCwMLKwMrGwMYOtISBg4mBjZmBg4VBhJWFiYONGUiwMLMATWMBEswsLMxAlngZ1KVgwJl0ocqhoo/LDsRJs5N2OHLj8m4Qe+3GPHuWM+L7QOy3k/ftmflt2X4QO3rhhv2n1zy0B7Edq0QPpMZLg9mZ36ftP9e7CazefSnHgZ4FB8DqRZVS93lv9gOrEQMAtnovU67qp3EAAAFAelRYdE1PTCByZGtpdCAyMDIyLjA5LjMAAHicfZJJbsMwDADvfgU/UIGLNh6TOCiKIjbQpv1D7/0/StqQmVwqmwAlDikumsDXx/z+8wvH4nmaAPCfX1XhWxBxuoErcL6+vi1wuZ/O4+Syfi33T1AgMhf7ntHTfb2NE4ILSFLqWhUwkRRBV3Bb4cnGccpcas/w4vaaawmQBigGYlJhsTwNpNxNDZAHmA30QCxcLSQlwZyRgpRBFlg2e1PlDJRaFew1wDzA6iE5iZTSm9krVvc4wDLA5iAlamoVeRaSe5MeZB1k30NaX7B39ymY1RszyDZI3ethFsvP7B1bZgmwD/C6zE8j2IdyXpc5hiImHL23TbRDNnuOPpJJiWaRSY2WkEmLwsmkR3W+1SiBTI6LCDfzcZO9JreXx0Ie0/b9eIamT397L4oCOLiUAgAAAPd6VFh0U01JTEVTIHJka2l0IDIwMjIuMDkuMwAAeJxljjtvwzAMhP9KgS4JIAt86UF6KrJkSdDd0JAC3Wo4CNotP76UM2ri3afjUcvpbNDel5NhW1xTwz640XI1aeyGLPmT5UYHd2ylHXukNuS354GjYtUSICInBg0zRaGUa5ggAmTJCVKYISoTq3aKUl2GuQeIKbueMDKIOHNRVClgLHmvmygyp6R+IUNWeoWwqHAvY6mF6x7zD8BelUBe9UTsLb5ZoQhxOIbb77Z+Pra7QVy3nw93l9v9+rd+fT8iGI4QjUZIxiNkkxGKpREmyyPMVkZYrI6wPv8BGWR5szJNProAAAAASUVORK5CYII=",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7fc65d27ee00>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, atom in enumerate(mols[1].GetAtoms()):\n",
    "    atom.SetProp('molAtomMapNumber', str(atom.GetIdx()))\n",
    "mols[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### how to make adjacent matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = None\n",
    "max_length = max_length if max_length is not None else mols[1].GetNumAtoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get directed graph\n",
    "begin, end = [b.GetBeginAtomIdx() for b in mols[1].GetBonds()], [b.GetEndAtomIdx() for b in mols[1].GetBonds()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros(shape=(max_length, max_length), dtype=np.int32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Bond Type\n",
    "*  bond type    32 sample  bond type   bond_encoder_m index set \n",
    "*  bond type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "bond_labels = [Chem.rdchem.BondType.ZERO] + list(sorted(set(bond.GetBondType()\n",
    "                                                            for mol in mols\n",
    "                                                            for bond in mol.GetBonds())))\n",
    "bond_encoder_m = {l: i for i, l in enumerate(bond_labels)}\n",
    "bond_type = [bond_encoder_m[b.GetBondType()] for b in mols[1].GetBonds()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bond_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make adjacent matrix\n",
    "# Position: connection, Value: bond type\n",
    "A[begin, end] = bond_type\n",
    "A[end, begin] = bond_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = np.sum(A[:mols[1].GetNumAtoms(), :mols[1].GetNumAtoms()], axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to make node tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_labels = sorted(set([atom.GetAtomicNum() for mol in mols for atom in mol.GetAtoms()] + [0]))\n",
    "atom_encoder_m = {l: i for i, l in enumerate(atom_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = np.array([\n",
    "        atom_encoder_m[atom.GetAtomicNum()] \n",
    "        for atom in mols[1].GetAtoms()\n",
    "        ] + [0] * ( max_length - mols[1].GetNumAtoms() ), dtype=np.int32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2onehot(labels, dim):\n",
    "    \"\"\"Convert label indices to one-hot vectors.\"\"\"\n",
    "    out = torch.zeros(list(labels.size()) + [dim]).to(device)\n",
    "    out.scatter_(len(out.size()) - 1, labels.unsqueeze(-1), 1.)\n",
    "    return out\n",
    "\n",
    "def sample_z(batch_size):\n",
    "    return np.random.normal(0, 1, size=(batch_size, z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = sample_z(a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  GPU         \n",
    "a = torch.from_numpy(a).to(device).long()  # Adjacency.\n",
    "x = torch.from_numpy(x).to(device).long()  # Nodes.\n",
    "a_tensor = label2onehot(a, b_dim)\n",
    "x_tensor = label2onehot(x, m_dim)\n",
    "z = torch.from_numpy(z).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_step = num_steps * epoch_i + a_step"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_tensor: Adjacent matrix\n",
    "# x_tensor: node\n",
    "logits_real, features_real = D(a_tensor, None, x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_logits, nodes_logits = G(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0911, -0.0470, -0.0090, -0.0958, -0.0946],\n",
       "        [ 0.1071, -0.0178, -0.0746, -0.1050, -0.0264],\n",
       "        [ 0.0137,  0.1275, -0.0112,  0.0491, -0.0787],\n",
       "        [-0.0253,  0.0735, -0.0187, -0.2184, -0.0090],\n",
       "        [ 0.0625, -0.1097,  0.0325, -0.0766,  0.0601],\n",
       "        [ 0.1707, -0.0236, -0.0806,  0.0390,  0.0553],\n",
       "        [-0.0055, -0.0256, -0.0614,  0.0788,  0.1004],\n",
       "        [ 0.1312,  0.0761,  0.0878,  0.1875, -0.1790],\n",
       "        [-0.0254,  0.1052, -0.2494, -0.0266,  0.0916]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(inputs, method, temperature=1.):\n",
    "    def listify(x):\n",
    "        return x if type(x) == list or type(x) == tuple else [x]\n",
    "\n",
    "    def delistify(x):\n",
    "        return x if len(x) > 1 else x[0]\n",
    "\n",
    "    if method == 'soft_gumbel':\n",
    "        softmax = [F.gumbel_softmax(e_logits.contiguous().view(-1, e_logits.size(-1))\n",
    "                                    / temperature, hard=False).view(e_logits.size())\n",
    "                   for e_logits in listify(inputs)]\n",
    "    elif method == 'hard_gumbel':\n",
    "        softmax = [F.gumbel_softmax(e_logits.contiguous().view(-1, e_logits.size(-1))\n",
    "                                    / temperature, hard=True).view(e_logits.size())\n",
    "                   for e_logits in listify(inputs)]\n",
    "    else:\n",
    "        softmax = [F.softmax(e_logits / temperature, -1)\n",
    "                   for e_logits in listify(inputs)]\n",
    "\n",
    "    return [delistify(e) for e in (softmax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'softmax'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "(edges_hat, nodes_hat) = postprocess((edges_logits, nodes_logits), post_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 9, 9, 5])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_fake, features_fake = D(edges_hat, None, nodes_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(y, x):\n",
    "    \"\"\"Compute gradient penalty: (L2_norm(dy/dx) - 1)**2.\"\"\"\n",
    "    weight = torch.ones(y.size()).to(device)\n",
    "    dydx = torch.autograd.grad(outputs=y,\n",
    "                               inputs=x,\n",
    "                               grad_outputs=weight,\n",
    "                               retain_graph=True,\n",
    "                               create_graph=True,\n",
    "                               only_inputs=True)[0]\n",
    "    dydx = dydx.view(dydx.size(0), -1)\n",
    "    dydx_l2norm = torch.sqrt(torch.sum(dydx ** 2, dim=1))\n",
    "    return torch.mean((dydx_l2norm - 1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute losses for gradient penalty.\n",
    "eps = torch.rand(logits_real.size(0), 1, 1, 1).to(device)\n",
    "x_int0 = (eps * a_tensor + (1. - eps) * edges_hat).requires_grad_(True)\n",
    "x_int1 = (eps.squeeze(-1) * x_tensor + (1. - eps.squeeze(-1)) * nodes_hat).requires_grad_(True)\n",
    "grad0, grad1 = D(x_int0, None, x_int1)\n",
    "grad_penalty = gradient_penalty(grad0, x_int0) + gradient_penalty(grad1, x_int1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_real = torch.mean(logits_real)\n",
    "d_loss_fake = torch.mean(logits_fake)\n",
    "loss_D = - d_loss_real + d_loss_fake + la_gp * grad_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses['l_D/R'].append(d_loss_real.item())\n",
    "losses['l_D/F'].append(d_loss_fake.item())\n",
    "losses['l_D'].append(loss_D.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    \"\"\"Reset the gradient buffers.\"\"\"\n",
    "    g_optimizer.zero_grad()\n",
    "    d_optimizer.zero_grad()\n",
    "    v_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_grad()\n",
    "loss_D.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_optimizer.state_dict()['state'][0]['square_avg']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'validity,qed'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(mols):\n",
    "    rr = 1.\n",
    "    for m in ('logp,sas,qed,unique' if metric == 'all' else metric).split(','):\n",
    "        if m == 'np':\n",
    "            rr *= MolecularMetrics.natural_product_scores(mols, norm=True)\n",
    "        elif m == 'logp':\n",
    "            rr *= MolecularMetrics.water_octanol_partition_coefficient_scores(mols, norm=True)\n",
    "        elif m == 'sas':\n",
    "            rr *= MolecularMetrics.synthetic_accessibility_score_scores(mols, norm=True)\n",
    "        elif m == 'qed':\n",
    "            rr *= MolecularMetrics.quantitative_estimation_druglikeness_scores(mols, norm=True)\n",
    "        elif m == 'novelty':\n",
    "            rr *= MolecularMetrics.novel_scores(mols, data)\n",
    "        elif m == 'dc':\n",
    "            rr *= MolecularMetrics.drugcandidate_scores(mols, data)\n",
    "        elif m == 'unique':\n",
    "            rr *= MolecularMetrics.unique_scores(mols)\n",
    "        elif m == 'diversity':\n",
    "            rr *= MolecularMetrics.diversity_scores(mols, data)\n",
    "        elif m == 'validity':\n",
    "            rr *= MolecularMetrics.valid_scores(mols)\n",
    "        else:\n",
    "            raise RuntimeError('{} is not defined as a metric'.format(m))\n",
    "    return rr.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(n_hat, e_hat, method):\n",
    "    (edges_hard, nodes_hard) = postprocess((e_hat, n_hat), method)\n",
    "    edges_hard, nodes_hard = torch.max(edges_hard, -1)[1], torch.max(nodes_hard, -1)[1]\n",
    "    mols = [data.matrices2mol(n_.data.cpu().numpy(), e_.data.cpu().numpy(), strict=True)\n",
    "            for e_, n_ in zip(edges_hard, nodes_hard)]\n",
    "    _reward = torch.from_numpy(reward(mols)).to(device)\n",
    "    return _reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-to-target\n",
    "edges_logits, nodes_logits = G(z)\n",
    "# Postprocess with Gumbel softmax\n",
    "(edges_hat, nodes_hat) = postprocess((edges_logits, nodes_logits), post_method)\n",
    "logits_fake, features_fake = D(edges_hat, None, nodes_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value losses\n",
    "value_logit_real, _ = V(a_tensor, None, x_tensor, torch.sigmoid)\n",
    "value_logit_fake, _ = V(edges_hat, None, nodes_hat, torch.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MolecularMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature mapping losses. Not used anywhere in the PyTorch version.\n",
    "# I include it here for the consistency with the TF code.\n",
    "f_loss = (torch.mean(features_real, 0) - torch.mean(features_fake, 0)) ** 2\n",
    "\n",
    "# Real Reward\n",
    "reward_r = torch.from_numpy(reward(mols)).to(device)\n",
    "# Fake Reward\n",
    "reward_f = get_reward(nodes_hat, edges_hat, post_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses Update\n",
    "loss_G = -logits_fake\n",
    "# Original TF loss_V. Here we use absolute values instead of the squared one.\n",
    "# loss_V = (value_logit_real - reward_r) ** 2 + (value_logit_fake - reward_f) ** 2\n",
    "loss_V = torch.abs(value_logit_real - reward_r) + torch.abs(value_logit_fake - reward_f)\n",
    "loss_RL = -value_logit_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_RL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_G = torch.mean(loss_G)\n",
    "loss_V = torch.mean(loss_V)\n",
    "loss_RL = torch.mean(loss_RL)\n",
    "losses['l_G'].append(loss_G.item())\n",
    "losses['l_RL'].append(loss_RL.item())\n",
    "losses['l_V'].append(loss_V.item())\n",
    "alpha = torch.abs(loss_G.detach() / loss_RL.detach()).detach()\n",
    "train_step_G = cur_la * loss_G + (1 - cur_la) * alpha * loss_RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/.pyenv/versions/3.9.2/envs/molgan/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: Error detected in AddmmBackward0. No forward pass information available. Enable detect anomaly during forward pass for more information. (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:92.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [512, 45]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Optimise value network.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mif\u001b[39;00m cur_step \u001b[39m%\u001b[39m n_critic \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 13\u001b[0m     train_step_V\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m##   .\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     v_optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/envs/molgan/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/envs/molgan/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [512, 45]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True) \n",
    "\n",
    "alpha = torch.abs(loss_G.detach() / loss_RL.detach()).detach()\n",
    "train_step_G = cur_la * loss_G + (1 - cur_la) * alpha * loss_RL\n",
    "train_step_V = loss_V\n",
    "reset_grad()\n",
    "# Optimise generator.\n",
    "if cur_step % n_critic == 0:\n",
    "    train_step_G.backward(retain_graph=True)\n",
    "    g_optimizer.step()\n",
    "# Optimise value network.\n",
    "if cur_step % n_critic == 0:\n",
    "    train_step_V.backward() ##   .\n",
    "    v_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # =================================================================================== #\n",
    "            #                               3. Train the generator                                #\n",
    "            # =================================================================================== #\n",
    "\n",
    "            # Z-to-target\n",
    "            edges_logits, nodes_logits = self.G(z)\n",
    "            # Postprocess with Gumbel softmax\n",
    "            (edges_hat, nodes_hat) = self.postprocess((edges_logits, nodes_logits), self.post_method)\n",
    "            logits_fake, features_fake = self.D(edges_hat, None, nodes_hat)\n",
    "\n",
    "            # Value losses\n",
    "            value_logit_real, _ = self.V(a_tensor, None, x_tensor, torch.sigmoid)\n",
    "            value_logit_fake, _ = self.V(edges_hat, None, nodes_hat, torch.sigmoid)\n",
    "\n",
    "            # Feature mapping losses. Not used anywhere in the PyTorch version.\n",
    "            # I include it here for the consistency with the TF code.\n",
    "            f_loss = (torch.mean(features_real, 0) - torch.mean(features_fake, 0)) ** 2\n",
    "\n",
    "            # Real Reward\n",
    "            reward_r = torch.from_numpy(self.reward(mols)).to(self.device)\n",
    "            # Fake Reward\n",
    "            reward_f = self.get_reward(nodes_hat, edges_hat, self.post_method)\n",
    "\n",
    "            # Losses Update\n",
    "            loss_G = -logits_fake\n",
    "            # Original TF loss_V. Here we use absolute values instead of the squared one.\n",
    "            # loss_V = (value_logit_real - reward_r) ** 2 + (value_logit_fake - reward_f) ** 2\n",
    "            loss_V = torch.abs(value_logit_real - reward_r) + torch.abs(value_logit_fake - reward_f)\n",
    "            loss_RL = -value_logit_fake\n",
    "\n",
    "            loss_G = torch.mean(loss_G)\n",
    "            loss_V = torch.mean(loss_V)\n",
    "            loss_RL = torch.mean(loss_RL)\n",
    "            losses['l_G'].append(loss_G.item())\n",
    "            losses['l_RL'].append(loss_RL.item())\n",
    "            losses['l_V'].append(loss_V.item())\n",
    "\n",
    "            alpha = torch.abs(loss_G.detach() / loss_RL.detach()).detach()\n",
    "            train_step_G = cur_la * loss_G + (1 - cur_la) * alpha * loss_RL\n",
    "\n",
    "            train_step_V = loss_V\n",
    "\n",
    "            if train_val_test == 'train':\n",
    "                self.reset_grad()\n",
    "\n",
    "                # Optimise generator.\n",
    "                if cur_step % self.n_critic == 0:\n",
    "                    train_step_G.backward(retain_graph=True)\n",
    "                    self.g_optimizer.step()\n",
    "\n",
    "                # Optimise value network.\n",
    "                if cur_step % self.n_critic == 0:\n",
    "                    train_step_V.backward()\n",
    "                    self.v_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "for i in range(start_epoch, num_epochs):\n",
    "    self.train_or_valid(epoch_i=i, train_val_test='train')\n",
    "    self.train_or_valid(epoch_i=i, train_val_test='val')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2021aad42aed9ec2de6443e4c206b312b12517efbcc0ff7ef55ad01c65ceb8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
