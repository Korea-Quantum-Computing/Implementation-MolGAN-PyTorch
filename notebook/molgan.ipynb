{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from rdkit import RDLogger\n",
    "from args import get_GAN_config\n",
    "from util_dir.utils_io import get_date_postfix\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Remove flooding logs.\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "import math\n",
    "\n",
    "import rdkit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.backends import cudnn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from pysmiles import read_smiles\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# TqdmWarning: IProgress not found. Please update jupyter and ipywidgets.\n",
    "# pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "config = get_GAN_config()\n",
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(z_dim=8, g_conv_dim=[128, 256, 512], d_conv_dim=[[128, 64], 128, [128, 64]], lambda_cls=1, lambda_rec=10, lambda_gp=10.0, post_method='softmax', batch_size=32, num_epochs=150, g_lr=0.0001, d_lr=0.0001, dropout=0.0, n_critic=5, resume_epoch=None, test_epochs=100, num_workers=1, mode='train', mol_data_dir='data/qm9_5k.sparsedataset', saving_dir='../exp_results/GAN/', log_step=1, sample_step=1000, model_save_step=1, lr_update_step=1000, lambda_wgan=0.0)\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.saving_dir = os.path.join(config.saving_dir, get_date_postfix())\n",
    "config.log_dir_path = os.path.join(config.saving_dir, 'log_dir')\n",
    "config.model_dir_path = os.path.join(config.saving_dir, 'model_dir')\n",
    "config.img_dir_path = os.path.join(config.saving_dir, 'img_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if not exist.\n",
    "if not os.path.exists(config.log_dir_path):\n",
    "    os.makedirs(config.log_dir_path)\n",
    "if not os.path.exists(config.model_dir_path):\n",
    "    os.makedirs(config.model_dir_path)\n",
    "if not os.path.exists(config.img_dir_path):\n",
    "    os.makedirs(config.img_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_name = os.path.join(config.log_dir_path, get_date_postfix() + '_logger.log')\n",
    "logging.basicConfig(filename=log_p_name, level=logging.INFO)\n",
    "logging.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.mol_data_dir = '../data/qm9_5k.sparsedataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.sparse_molecular_dataset import SparseMolecularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SparseMolecularDataset()\n",
    "data.load(config.mol_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Model configurations.\n",
    "z_dim = config.z_dim\n",
    "m_dim = data.atom_num_types\n",
    "b_dim = data.bond_num_types\n",
    "g_conv_dim = config.g_conv_dim\n",
    "d_conv_dim = config.d_conv_dim\n",
    "la = config.lambda_wgan\n",
    "lambda_rec = config.lambda_rec\n",
    "la_gp = config.lambda_gp\n",
    "post_method = config.post_method\n",
    "metric = 'validity,qed'\n",
    "# Training configurations.\n",
    "batch_size = config.batch_size\n",
    "num_epochs = config.num_epochs\n",
    "num_steps = (len(data) // batch_size)\n",
    "g_lr = config.g_lr\n",
    "d_lr = config.d_lr\n",
    "dropout = config.dropout\n",
    "if  la > 0:\n",
    "    n_critic = config.n_critic\n",
    "else:\n",
    "    n_critic = 1\n",
    "resume_epoch = config.resume_epoch\n",
    "# Training or testing.\n",
    "mode = config.mode\n",
    "\n",
    "# Miscellaneous.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: ', device)\n",
    "# Directories.\n",
    "log_dir_path = config.log_dir_path\n",
    "model_dir_path = config.model_dir_path\n",
    "img_dir_path = config.img_dir_path\n",
    "\n",
    "# Step size.\n",
    "model_save_step = config.model_save_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiDenseLayer(Module):\n",
    "    # aux_unit = 8, linear_units = [128, 256, 512], activation = Tanh()\n",
    "    def __init__(self, aux_unit, linear_units, activation=None, dropout_rate=0.):\n",
    "        super(MultiDenseLayer, self).__init__()\n",
    "        layers = []\n",
    "        for c0, c1 in zip([aux_unit] + linear_units[:-1], linear_units):\n",
    "            layers.append(nn.Linear(c0, c1))\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            if activation is not None:\n",
    "                layers.append(activation)\n",
    "        self.linear_layer = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        h = self.linear_layer(inputs)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiGraphConvolutionLayers(Module):\n",
    "    # in_features: 5, units: [128, 64], activation: Tanh, edge_type_num: 4,\n",
    "    # with_features: False, f_dim: 0, dropout_rate = 0\n",
    "    def __init__(self, in_features, units, activation, edge_type_num, with_features=False, f=0, dropout_rate=0.):\n",
    "        super(MultiGraphConvolutionLayers, self).__init__()\n",
    "        self.conv_nets = nn.ModuleList()\n",
    "        self.units = units\n",
    "        in_units = []\n",
    "        if with_features:\n",
    "            for i in range(len(self.units)):\n",
    "                in_units = list([x + in_features for x in self.units])\n",
    "            for u0, u1 in zip([in_features+f] + in_units[:-1], self.units):\n",
    "                self.conv_nets.append(GraphConvolutionLayer(u0, u1, activation, edge_type_num, dropout_rate))\n",
    "        else:\n",
    "            for i in range(len(self.units)):\n",
    "                in_units = list([x + in_features for x in self.units])\n",
    "            for u0, u1 in zip([in_features] + in_units[:-1], self.units):\n",
    "                self.conv_nets.append(GraphConvolutionLayer(u0, u1, activation, edge_type_num, dropout_rate))\n",
    "\n",
    "    def forward(self, n_tensor, adj_tensor, h_tensor=None):\n",
    "        hidden_tensor = h_tensor\n",
    "        for conv_idx in range(len(self.units)):\n",
    "            hidden_tensor = self.conv_nets[conv_idx](n_tensor, adj_tensor, hidden_tensor)\n",
    "        return hidden_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(Module):\n",
    "    # in_features: 5, graph_conv_units: [128, 64], edge_type_num: 4, with_features: False, f_dim: 0, dropout_rate: 0\n",
    "    def __init__(self, in_features, graph_conv_units, edge_type_num, with_features=False, f_dim=0, dropout_rate=0.):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.graph_conv_units = graph_conv_units\n",
    "        self.activation_f = torch.nn.Tanh()\n",
    "        # in_features: 5, self.graph_conv_units: [128, 64], self.activation_f: Tanh, edge_type_num: 4,\n",
    "        # with_features: False, f_dim: 0, dropout_rate = 0\n",
    "        self.multi_graph_convolution_layers = \\\n",
    "            MultiGraphConvolutionLayers(in_features, self.graph_conv_units, self.activation_f, edge_type_num,\n",
    "                                        with_features, f_dim, dropout_rate)\n",
    "\n",
    "    def forward(self, n_tensor, adj_tensor, h_tensor=None):\n",
    "        output = self.multi_graph_convolution_layers(n_tensor, adj_tensor, h_tensor)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolutionLayer(Module):\n",
    "    # in_features = 5, u = graph_conv_units = 128, activation_f = Tanh, edge_type_num = 5                                    \n",
    "    def __init__(self, in_features, u, activation, edge_type_num, dropout_rate=0.):\n",
    "        super(GraphConvolutionLayer, self).__init__()\n",
    "        self.edge_type_num = edge_type_num\n",
    "        self.u = u\n",
    "        self.adj_list = nn.ModuleList()\n",
    "        # Edge type specific linear transformation.\n",
    "        for _ in range(self.edge_type_num):\n",
    "            self.adj_list.append(nn.Linear(in_features, u))\n",
    "        # Self-connected linear transformation.\n",
    "        self.linear_2 = nn.Linear(in_features, u)\n",
    "        self.activation = activation\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, n_tensor, adj_tensor, h_tensor=None):\n",
    "        # When Additional features are used.\n",
    "        if h_tensor is not None:\n",
    "            annotations = torch.cat((n_tensor, h_tensor), -1)\n",
    "        else:\n",
    "            annotations = n_tensor\n",
    "        # output: [batch_size, edge_type_num, u]\n",
    "        output = torch.stack([self.adj_list[i](annotations) for i in range(self.edge_type_num)], 1)\n",
    "        # output: [batch_size, u]\n",
    "        output = torch.matmul(adj_tensor, output)\n",
    "        # out_sum: [batch_size, 1]\n",
    "        out_sum = torch.sum(output, 1)\n",
    "        out_linear_2 = self.linear_2(annotations)\n",
    "        output = out_sum + out_linear_2\n",
    "        output = self.activation(output) if self.activation is not None else output\n",
    "        output = self.dropout(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAggregation(Module):\n",
    "    # Readout layer.\n",
    "    def __init__(self, in_features, aux_units, activation, with_features=False, f_dim=0,\n",
    "                 dropout_rate=0.):\n",
    "        super(GraphAggregation, self).__init__()\n",
    "        self.with_features = with_features\n",
    "        self.activation = activation\n",
    "        if self.with_features:\n",
    "            self.i = nn.Sequential(nn.Linear(in_features+f_dim, aux_units),\n",
    "                                   nn.Sigmoid())\n",
    "            j_layers = [nn.Linear(in_features+f_dim, aux_units)]\n",
    "            if self.activation is not None:\n",
    "                j_layers.append(self.activation)\n",
    "            self.j = nn.Sequential(*j_layers)\n",
    "        else:\n",
    "            self.i = nn.Sequential(nn.Linear(in_features, aux_units),\n",
    "                                   nn.Sigmoid())\n",
    "            j_layers = [nn.Linear(in_features, aux_units)]\n",
    "            if self.activation is not None:\n",
    "                j_layers.append(self.activation)\n",
    "            self.j = nn.Sequential(*j_layers)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, n_tensor, out_tensor, h_tensor=None):\n",
    "        if h_tensor is not None:\n",
    "            annotations = torch.cat((out_tensor, h_tensor, n_tensor), -1)\n",
    "        else:\n",
    "            annotations = torch.cat((out_tensor, n_tensor), -1)\n",
    "        # The i here seems to be an attention.\n",
    "        i = self.i(annotations)\n",
    "        j = self.j(annotations)\n",
    "        output = torch.sum(torch.mul(i, j), 1)\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator network.\"\"\"\n",
    "    # conv_dims = [128, 256, 512], z_dim = 8, vertexes = 9, edges = 5, nodes = 5, dropout = 0.0\n",
    "    def __init__(self, conv_dims, z_dim, vertexes, edges, nodes, dropout_rate):\n",
    "        super(Generator, self).__init__()\n",
    "        self.activation_f = torch.nn.Tanh()\n",
    "        # z_dim = 8, conv_dims = [128, 256, 512], activation = Tanh()\n",
    "        self.multi_dense_layer = MultiDenseLayer(z_dim, conv_dims, self.activation_f)\n",
    "        self.vertexes = vertexes\n",
    "        self.edges = edges\n",
    "        self.nodes = nodes\n",
    "        # edges_layer 512 -> edges * vertexes * vertexes = 5 * 9 * 9 = 405\n",
    "        self.edges_layer = nn.Linear(conv_dims[-1], edges * vertexes * vertexes)\n",
    "        # node_layer 512 -> vertexes * nodes = 9 * 5 = 45\n",
    "        self.nodes_layer = nn.Linear(conv_dims[-1], vertexes * nodes)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 8 -> 128 -> 256 -> 512\n",
    "        output = self.multi_dense_layer(x)\n",
    "        # 405 -> batch_size * 5 * 9 * 9\n",
    "        edges_logits = self.edges_layer(output).view(-1, self.edges, self.vertexes, self.vertexes)\n",
    "        # Change the order of the dimensions: batch_size * 5 * 9 * 9 -> batch_size * 5 * 9 * 9\n",
    "        # Average the matrix and its transpose: (A + A^T) / 2\n",
    "        edges_logits = (edges_logits + edges_logits.permute(0, 1, 3, 2)) / 2\n",
    "        # batch_size * 5 * 9 * 9 -> batch_size * 9 * 9 * 5\n",
    "        edges_logits = self.dropout(edges_logits.permute(0, 2, 3, 1))\n",
    "\n",
    "        # 512 -> 45\n",
    "        nodes_logits = self.nodes_layer(output)\n",
    "        # 45 -> batch_size * 9 * 5\n",
    "        nodes_logits = self.dropout(nodes_logits.view(-1, self.vertexes, self.nodes))\n",
    "\n",
    "        return edges_logits, nodes_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator network with PatchGAN.\"\"\"\n",
    "    # conv_dim: [[128, 64], 128, [128, 64]], m_dim: 5, b_dim: 4\n",
    "    def __init__(self, conv_dim, m_dim, b_dim, with_features=False, f_dim=0, dropout_rate=0.):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.activation_f = torch.nn.Tanh()\n",
    "        # graph_conv_dim = [128, 64], aux_dim = 128, linear_dim = [128, 64]\n",
    "        graph_conv_dim, aux_dim, linear_dim = conv_dim\n",
    "        # discriminator\n",
    "        # m_dim: 5, graph_conv_dim: [128, 64], b_dim: 4, with_features: False, f_dim: 0, dropout_rate: 0\n",
    "        self.gcn_layer = GraphConvolution(m_dim, graph_conv_dim, b_dim, with_features, f_dim, dropout_rate)\n",
    "        self.agg_layer = GraphAggregation(graph_conv_dim[-1] + m_dim, aux_dim, self.activation_f, with_features, f_dim,\n",
    "                                          dropout_rate)\n",
    "        self.multi_dense_layer = MultiDenseLayer(aux_dim, linear_dim, self.activation_f, dropout_rate=dropout_rate)\n",
    "\n",
    "        self.output_layer = nn.Linear(linear_dim[-1], 1)\n",
    "\n",
    "    # adj = 32 * 9 * 9 * 5, hidden = 32 * 9 * 128, node = 32 * 9 * 5\n",
    "    def forward(self, adj, hidden, node, activation=None):\n",
    "        adj = adj[:, :, :, 1:].permute(0, 3, 1, 2)\n",
    "        h_1 = self.gcn_layer(node, adj, hidden)\n",
    "        h = self.agg_layer(h_1, node, hidden)\n",
    "        h = self.multi_dense_layer(h)\n",
    "\n",
    "        output = self.output_layer(h)\n",
    "        output = activation(output) if activation is not None else output\n",
    "\n",
    "        return output, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(g_conv_dim,\n",
    "          z_dim,\n",
    "          data.vertexes,\n",
    "          data.bond_num_types,\n",
    "          data.atom_num_types,\n",
    "          dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator(d_conv_dim, m_dim, b_dim - 1, dropout)\n",
    "V = Discriminator(d_conv_dim, m_dim, b_dim - 1, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_network(model, name, log=None):\n",
    "    \"\"\"Print out the network information.\"\"\"\n",
    "    num_params = 0\n",
    "    for p in model.parameters():\n",
    "        num_params += p.numel()\n",
    "    print(model)\n",
    "    print(name)\n",
    "    print(\"The number of parameters: {}\".format(num_params))\n",
    "    if log is not None:\n",
    "        log.info(model)\n",
    "        log.info(name)\n",
    "        log.info(\"The number of parameters: {}\".format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (activation_f): Tanh()\n",
      "  (multi_dense_layer): MultiDenseLayer(\n",
      "    (linear_layer): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Tanh()\n",
      "      (3): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (4): Dropout(p=0.0, inplace=False)\n",
      "      (5): Tanh()\n",
      "      (6): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (7): Dropout(p=0.0, inplace=False)\n",
      "      (8): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (edges_layer): Linear(in_features=512, out_features=405, bias=True)\n",
      "  (nodes_layer): Linear(in_features=512, out_features=45, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "G\n",
      "The number of parameters: 396610\n",
      "Discriminator(\n",
      "  (activation_f): Tanh()\n",
      "  (gcn_layer): GraphConvolution(\n",
      "    (activation_f): Tanh()\n",
      "    (multi_graph_convolution_layers): MultiGraphConvolutionLayers(\n",
      "      (conv_nets): ModuleList(\n",
      "        (0): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (1): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (2): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (3): Linear(in_features=5, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=5, out_features=128, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (1): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (2): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (3): Linear(in_features=133, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=133, out_features=64, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (agg_layer): GraphAggregation(\n",
      "    (activation): Tanh()\n",
      "    (i): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (j): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (multi_dense_layer): MultiDenseLayer(\n",
      "    (linear_layer): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Tanh()\n",
      "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (4): Dropout(p=0.0, inplace=False)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "D\n",
      "The number of parameters: 89473\n",
      "Discriminator(\n",
      "  (activation_f): Tanh()\n",
      "  (gcn_layer): GraphConvolution(\n",
      "    (activation_f): Tanh()\n",
      "    (multi_graph_convolution_layers): MultiGraphConvolutionLayers(\n",
      "      (conv_nets): ModuleList(\n",
      "        (0): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (1): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (2): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (3): Linear(in_features=5, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=5, out_features=128, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (1): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (2): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (3): Linear(in_features=133, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=133, out_features=64, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (agg_layer): GraphAggregation(\n",
      "    (activation): Tanh()\n",
      "    (i): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (j): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (multi_dense_layer): MultiDenseLayer(\n",
      "    (linear_layer): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Tanh()\n",
      "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (4): Dropout(p=0.0, inplace=False)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "V\n",
      "The number of parameters: 89473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (activation_f): Tanh()\n",
       "  (gcn_layer): GraphConvolution(\n",
       "    (activation_f): Tanh()\n",
       "    (multi_graph_convolution_layers): MultiGraphConvolutionLayers(\n",
       "      (conv_nets): ModuleList(\n",
       "        (0): GraphConvolutionLayer(\n",
       "          (adj_list): ModuleList(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (3): Linear(in_features=5, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear_2): Linear(in_features=5, out_features=128, bias=True)\n",
       "          (activation): Tanh()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GraphConvolutionLayer(\n",
       "          (adj_list): ModuleList(\n",
       "            (0): Linear(in_features=133, out_features=64, bias=True)\n",
       "            (1): Linear(in_features=133, out_features=64, bias=True)\n",
       "            (2): Linear(in_features=133, out_features=64, bias=True)\n",
       "            (3): Linear(in_features=133, out_features=64, bias=True)\n",
       "          )\n",
       "          (linear_2): Linear(in_features=133, out_features=64, bias=True)\n",
       "          (activation): Tanh()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (agg_layer): GraphAggregation(\n",
       "    (activation): Tanh()\n",
       "    (i): Sequential(\n",
       "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (j): Sequential(\n",
       "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (multi_dense_layer): MultiDenseLayer(\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): Dropout(p=0.0, inplace=False)\n",
       "      (2): Tanh()\n",
       "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (4): Dropout(p=0.0, inplace=False)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_optimizer = torch.optim.RMSprop(G.parameters(), g_lr)\n",
    "d_optimizer = torch.optim.RMSprop(D.parameters(), d_lr)\n",
    "v_optimizer = torch.optim.RMSprop(V.parameters(), g_lr)\n",
    "print_network(G, 'G', logging)\n",
    "print_network(D, 'D', logging)\n",
    "print_network(V, 'V', logging)\n",
    "\n",
    "G.to(device)\n",
    "D.to(device)\n",
    "V.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (activation_f): Tanh()\n",
      "  (multi_dense_layer): MultiDenseLayer(\n",
      "    (linear_layer): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Tanh()\n",
      "      (3): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (4): Dropout(p=0.0, inplace=False)\n",
      "      (5): Tanh()\n",
      "      (6): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (7): Dropout(p=0.0, inplace=False)\n",
      "      (8): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (edges_layer): Linear(in_features=512, out_features=405, bias=True)\n",
      "  (nodes_layer): Linear(in_features=512, out_features=45, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "G\n",
      "The number of parameters: 396610\n"
     ]
    }
   ],
   "source": [
    "print_network(G, 'G', logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (activation_f): Tanh()\n",
      "  (gcn_layer): GraphConvolution(\n",
      "    (activation_f): Tanh()\n",
      "    (multi_graph_convolution_layers): MultiGraphConvolutionLayers(\n",
      "      (conv_nets): ModuleList(\n",
      "        (0): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (1): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (2): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (3): Linear(in_features=5, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=5, out_features=128, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (1): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (2): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (3): Linear(in_features=133, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=133, out_features=64, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (agg_layer): GraphAggregation(\n",
      "    (activation): Tanh()\n",
      "    (i): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (j): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (multi_dense_layer): MultiDenseLayer(\n",
      "    (linear_layer): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Tanh()\n",
      "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (4): Dropout(p=0.0, inplace=False)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "D\n",
      "The number of parameters: 89473\n"
     ]
    }
   ],
   "source": [
    "print_network(D, 'D', logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (activation_f): Tanh()\n",
      "  (gcn_layer): GraphConvolution(\n",
      "    (activation_f): Tanh()\n",
      "    (multi_graph_convolution_layers): MultiGraphConvolutionLayers(\n",
      "      (conv_nets): ModuleList(\n",
      "        (0): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (1): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (2): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (3): Linear(in_features=5, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=5, out_features=128, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (1): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (2): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (3): Linear(in_features=133, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=133, out_features=64, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (agg_layer): GraphAggregation(\n",
      "    (activation): Tanh()\n",
      "    (i): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (j): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (multi_dense_layer): MultiDenseLayer(\n",
      "    (linear_layer): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Tanh()\n",
      "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (4): Dropout(p=0.0, inplace=False)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "V\n",
      "The number of parameters: 89473\n"
     ]
    }
   ],
   "source": [
    "print_network(V, 'V', logging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_la = la\n",
    "epoch_i = 0\n",
    "a_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "losses = defaultdict(list)\n",
    "scores = defaultdict(list)\n",
    "the_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, smiles, data_S, data_A, data_X, data_D, data_F, data_Le, data_Lv\n",
    "# a: Adjacent matrix,\n",
    "# x: node \n",
    "mols, smiles, _, a, x, _, _, _, _ = data.next_train_batch(batch_size) # generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate single data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### molecular graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol object at 0x7fef90f8cef0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mols[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CC1CC12CC1(O)CC12'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### molecular graph with detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol object at 0x7fef90f8cef0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, atom in enumerate(mols[1].GetAtoms()):\n",
    "    atom.SetProp('molAtomMapNumber', str(atom.GetIdx()))\n",
    "mols[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### how to make adjacent matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = None\n",
    "max_length = max_length if max_length is not None else mols[1].GetNumAtoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 5, 7, 3, 8, 8]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b.GetBeginAtomIdx() for b in mols[1].GetBonds()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 1, 5, 3]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b.GetEndAtomIdx() for b in mols[1].GetBonds()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get directed graph\n",
    "begin, end = [b.GetBeginAtomIdx() for b in mols[1].GetBonds()], [b.GetEndAtomIdx() for b in mols[1].GetBonds()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros(shape=(max_length, max_length), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Bond Type\n",
    "*  bond type    32 sample  bond type   bond_encoder_m index set \n",
    "*  bond type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "bond_labels = [Chem.rdchem.BondType.ZERO] + list(sorted(set(bond.GetBondType()\n",
    "                                                            for mol in mols\n",
    "                                                            for bond in mol.GetBonds())))\n",
    "bond_encoder_m = {l: i for i, l in enumerate(bond_labels)}\n",
    "bond_type = [bond_encoder_m[b.GetBondType()] for b in mols[1].GetBonds()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bond_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make adjacent matrix\n",
    "# Position: connection, Value: bond type\n",
    "A[begin, end] = bond_type\n",
    "A[end, begin] = bond_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bond_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = np.sum(A[:mols[1].GetNumAtoms(), :mols[1].GetNumAtoms()], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 4, 2, 4, 1, 2, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to make node tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_labels = sorted(set([atom.GetAtomicNum() for mol in mols for atom in mol.GetAtoms()] + [0]))\n",
    "atom_encoder_m = {l: i for i, l in enumerate(atom_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 6: 1, 7: 2, 8: 3, 9: 4}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_encoder_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = np.array([\n",
    "        atom_encoder_m[atom.GetAtomicNum()] \n",
    "        for atom in mols[1].GetAtoms()\n",
    "        ] + [0] * ( max_length - mols[1].GetNumAtoms() ), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2onehot(labels, dim):\n",
    "    \"\"\"Convert label indices to one-hot vectors.\"\"\"\n",
    "    out = torch.zeros(list(labels.size()) + [dim]).to(device)\n",
    "    out.scatter_(len(out.size()) - 1, labels.unsqueeze(-1), 1.)\n",
    "    return out\n",
    "\n",
    "def sample_z(batch_size):\n",
    "    return np.random.normal(0, 1, size=(batch_size, z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = sample_z(a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  GPU         \n",
    "a = torch.from_numpy(a).to(device).long()  # Adjacency.\n",
    "x = torch.from_numpy(x).to(device).long()  # Nodes.\n",
    "a_tensor = label2onehot(a, b_dim)\n",
    "x_tensor = label2onehot(x, m_dim)\n",
    "z = torch.from_numpy(z).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_step = num_steps * epoch_i + a_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_tensor: Adjacent matrix\n",
    "# x_tensor: node\n",
    "logits_real, features_real = D(a_tensor, None, x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 9, 5])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_logits, nodes_logits = G(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 9, 9, 5])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(inputs, method, temperature=1.):\n",
    "    def listify(x):\n",
    "        return x if type(x) == list or type(x) == tuple else [x]\n",
    "\n",
    "    def delistify(x):\n",
    "        return x if len(x) > 1 else x[0]\n",
    "\n",
    "    if method == 'soft_gumbel':\n",
    "        softmax = [F.gumbel_softmax(e_logits.contiguous().view(-1, e_logits.size(-1))\n",
    "                                    / temperature, hard=False).view(e_logits.size())\n",
    "                   for e_logits in listify(inputs)]\n",
    "    elif method == 'hard_gumbel':\n",
    "        softmax = [F.gumbel_softmax(e_logits.contiguous().view(-1, e_logits.size(-1))\n",
    "                                    / temperature, hard=True).view(e_logits.size())\n",
    "                   for e_logits in listify(inputs)]\n",
    "    else:\n",
    "        softmax = [F.softmax(e_logits / temperature, -1)\n",
    "                   for e_logits in listify(inputs)]\n",
    "\n",
    "    return [delistify(e) for e in (softmax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "(edges_hat, nodes_hat) = postprocess((edges_logits, nodes_logits), post_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 9, 5])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 9])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_hat[1, :, :, 4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_fake, features_fake = D(edges_hat, None, nodes_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_fake[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(y, x):\n",
    "    \"\"\"Compute gradient penalty: (L2_norm(dy/dx) - 1)**2.\"\"\"\n",
    "    weight = torch.ones(y.size()).to(device)\n",
    "    dydx = torch.autograd.grad(outputs=y,\n",
    "                               inputs=x,\n",
    "                               grad_outputs=weight,\n",
    "                               retain_graph=True,\n",
    "                               create_graph=True,\n",
    "                               only_inputs=True)[0]\n",
    "    dydx = dydx.view(dydx.size(0), -1)\n",
    "    dydx_l2norm = torch.sqrt(torch.sum(dydx ** 2, dim=1))\n",
    "    return torch.mean((dydx_l2norm - 1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute losses for gradient penalty.\n",
    "eps = torch.rand(logits_real.size(0), 1, 1, 1).to(device)\n",
    "x_int0 = (eps * a_tensor + (1. - eps) * edges_hat).requires_grad_(True)\n",
    "x_int1 = (eps.squeeze(-1) * x_tensor + (1. - eps.squeeze(-1)) * nodes_hat).requires_grad_(True)\n",
    "grad0, grad1 = D(x_int0, None, x_int1)\n",
    "grad_penalty = gradient_penalty(grad0, x_int0) + gradient_penalty(grad1, x_int1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_real = torch.mean(logits_real)\n",
    "d_loss_fake = torch.mean(logits_fake)\n",
    "loss_D = - d_loss_real + d_loss_fake + la_gp * grad_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses['l_D/R'].append(d_loss_real.item())\n",
    "losses['l_D/F'].append(d_loss_fake.item())\n",
    "losses['l_D'].append(loss_D.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'l_D/R': [0.30454879999160767],\n",
       "             'l_D/F': [0.0014736459124833345],\n",
       "             'l_D': [7.486253261566162]})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    \"\"\"Reset the gradient buffers.\"\"\"\n",
    "    g_optimizer.zero_grad()\n",
    "    d_optimizer.zero_grad()\n",
    "    v_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_grad()\n",
    "loss_D.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_optimizer.state_dict()['state'][0]['square_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'validity,qed'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(mols):\n",
    "    rr = 1.\n",
    "    for m in ('logp,sas,qed,unique' if metric == 'all' else metric).split(','):\n",
    "        if m == 'np':\n",
    "            rr *= MolecularMetrics.natural_product_scores(mols, norm=True)\n",
    "        elif m == 'logp':\n",
    "            rr *= MolecularMetrics.water_octanol_partition_coefficient_scores(mols, norm=True)\n",
    "        elif m == 'sas':\n",
    "            rr *= MolecularMetrics.synthetic_accessibility_score_scores(mols, norm=True)\n",
    "        elif m == 'qed':\n",
    "            rr *= MolecularMetrics.quantitative_estimation_druglikeness_scores(mols, norm=True)\n",
    "        elif m == 'novelty':\n",
    "            rr *= MolecularMetrics.novel_scores(mols, data)\n",
    "        elif m == 'dc':\n",
    "            rr *= MolecularMetrics.drugcandidate_scores(mols, data)\n",
    "        elif m == 'unique':\n",
    "            rr *= MolecularMetrics.unique_scores(mols)\n",
    "        elif m == 'diversity':\n",
    "            rr *= MolecularMetrics.diversity_scores(mols, data)\n",
    "        elif m == 'validity':\n",
    "            rr *= MolecularMetrics.valid_scores(mols)\n",
    "        else:\n",
    "            raise RuntimeError('{} is not defined as a metric'.format(m))\n",
    "    return rr.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(n_hat, e_hat, method):\n",
    "    (edges_hard, nodes_hard) = postprocess((e_hat, n_hat), method)\n",
    "    edges_hard, nodes_hard = torch.max(edges_hard, -1)[1], torch.max(nodes_hard, -1)[1]\n",
    "    mols = [data.matrices2mol(n_.data.cpu().numpy(), e_.data.cpu().numpy(), strict=True)\n",
    "            for e_, n_ in zip(edges_hard, nodes_hard)]\n",
    "    _reward = torch.from_numpy(reward(mols)).to(device)\n",
    "    return _reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-to-target\n",
    "edges_logits, nodes_logits = G(z)\n",
    "# Postprocess with Gumbel softmax\n",
    "(edges_hat, nodes_hat) = postprocess((edges_logits, nodes_logits), post_method)\n",
    "logits_fake, features_fake = D(edges_hat, None, nodes_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value losses\n",
    "value_logit_real, _ = V(a_tensor, None, x_tensor, torch.sigmoid)\n",
    "value_logit_fake, _ = V(edges_hat, None, nodes_hat, torch.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MolecularMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature mapping losses. Not used anywhere in the PyTorch version.\n",
    "# I include it here for the consistency with the TF code.\n",
    "f_loss = (torch.mean(features_real, 0) - torch.mean(features_fake, 0)) ** 2\n",
    "\n",
    "# Real Reward\n",
    "reward_r = torch.from_numpy(reward(mols)).to(device)\n",
    "# Fake Reward\n",
    "reward_f = get_reward(nodes_hat, edges_hat, post_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses Update\n",
    "loss_G = -logits_fake\n",
    "# Original TF loss_V. Here we use absolute values instead of the squared one.\n",
    "# loss_V = (value_logit_real - reward_r) ** 2 + (value_logit_fake - reward_f) ** 2\n",
    "loss_V = torch.abs(value_logit_real - reward_r) + torch.abs(value_logit_fake - reward_f)\n",
    "loss_RL = -value_logit_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_RL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_G = torch.mean(loss_G)\n",
    "loss_V = torch.mean(loss_V)\n",
    "loss_RL = torch.mean(loss_RL)\n",
    "losses['l_G'].append(loss_G.item())\n",
    "losses['l_RL'].append(loss_RL.item())\n",
    "losses['l_V'].append(loss_V.item())\n",
    "alpha = torch.abs(loss_G.detach() / loss_RL.detach()).detach()\n",
    "train_step_G = cur_la * loss_G + (1 - cur_la) * alpha * loss_RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/.pyenv/versions/3.9.2/envs/molgan/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: Error detected in AddmmBackward0. No forward pass information available. Enable detect anomaly during forward pass for more information. (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:92.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [512, 45]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Optimise value network.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mif\u001b[39;00m cur_step \u001b[39m%\u001b[39m n_critic \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 13\u001b[0m     train_step_V\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m##   .\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     v_optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/envs/molgan/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/envs/molgan/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [512, 45]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True) \n",
    "\n",
    "alpha = torch.abs(loss_G.detach() / loss_RL.detach()).detach()\n",
    "train_step_G = cur_la * loss_G + (1 - cur_la) * alpha * loss_RL\n",
    "train_step_V = loss_V\n",
    "reset_grad()\n",
    "# Optimise generator.\n",
    "if cur_step % n_critic == 0:\n",
    "    train_step_G.backward(retain_graph=True)\n",
    "    g_optimizer.step()\n",
    "# Optimise value network.\n",
    "if cur_step % n_critic == 0:\n",
    "    train_step_V.backward() ##   .\n",
    "    v_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # =================================================================================== #\n",
    "            #                               3. Train the generator                                #\n",
    "            # =================================================================================== #\n",
    "\n",
    "            # Z-to-target\n",
    "            edges_logits, nodes_logits = self.G(z)\n",
    "            # Postprocess with Gumbel softmax\n",
    "            (edges_hat, nodes_hat) = self.postprocess((edges_logits, nodes_logits), self.post_method)\n",
    "            logits_fake, features_fake = self.D(edges_hat, None, nodes_hat)\n",
    "\n",
    "            # Value losses\n",
    "            value_logit_real, _ = self.V(a_tensor, None, x_tensor, torch.sigmoid)\n",
    "            value_logit_fake, _ = self.V(edges_hat, None, nodes_hat, torch.sigmoid)\n",
    "\n",
    "            # Feature mapping losses. Not used anywhere in the PyTorch version.\n",
    "            # I include it here for the consistency with the TF code.\n",
    "            f_loss = (torch.mean(features_real, 0) - torch.mean(features_fake, 0)) ** 2\n",
    "\n",
    "            # Real Reward\n",
    "            reward_r = torch.from_numpy(self.reward(mols)).to(self.device)\n",
    "            # Fake Reward\n",
    "            reward_f = self.get_reward(nodes_hat, edges_hat, self.post_method)\n",
    "\n",
    "            # Losses Update\n",
    "            loss_G = -logits_fake\n",
    "            # Original TF loss_V. Here we use absolute values instead of the squared one.\n",
    "            # loss_V = (value_logit_real - reward_r) ** 2 + (value_logit_fake - reward_f) ** 2\n",
    "            loss_V = torch.abs(value_logit_real - reward_r) + torch.abs(value_logit_fake - reward_f)\n",
    "            loss_RL = -value_logit_fake\n",
    "\n",
    "            loss_G = torch.mean(loss_G)\n",
    "            loss_V = torch.mean(loss_V)\n",
    "            loss_RL = torch.mean(loss_RL)\n",
    "            losses['l_G'].append(loss_G.item())\n",
    "            losses['l_RL'].append(loss_RL.item())\n",
    "            losses['l_V'].append(loss_V.item())\n",
    "\n",
    "            alpha = torch.abs(loss_G.detach() / loss_RL.detach()).detach()\n",
    "            train_step_G = cur_la * loss_G + (1 - cur_la) * alpha * loss_RL\n",
    "\n",
    "            train_step_V = loss_V\n",
    "\n",
    "            if train_val_test == 'train':\n",
    "                self.reset_grad()\n",
    "\n",
    "                # Optimise generator.\n",
    "                if cur_step % self.n_critic == 0:\n",
    "                    train_step_G.backward(retain_graph=True)\n",
    "                    self.g_optimizer.step()\n",
    "\n",
    "                # Optimise value network.\n",
    "                if cur_step % self.n_critic == 0:\n",
    "                    train_step_V.backward()\n",
    "                    self.v_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "for i in range(start_epoch, num_epochs):\n",
    "    self.train_or_valid(epoch_i=i, train_val_test='train')\n",
    "    self.train_or_valid(epoch_i=i, train_val_test='val')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
