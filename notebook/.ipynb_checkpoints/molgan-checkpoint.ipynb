{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from rdkit import RDLogger\n",
    "from args import get_GAN_config\n",
    "from util_dir.utils_io import get_date_postfix\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Remove flooding logs.\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "import rdkit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.backends import cudnn\n",
    "\n",
    "\n",
    "from pysmiles import read_smiles\n",
    "from layers import GraphConvolution, GraphAggregation, MultiGraphConvolutionLayers, MultiDenseLayer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# TqdmWarning: IProgress not found. Please update jupyter and ipywidgets.\n",
    "# pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "config = get_GAN_config()\n",
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(z_dim=8, g_conv_dim=[128, 256, 512], d_conv_dim=[[128, 64], 128, [128, 64]], lambda_cls=1, lambda_rec=10, lambda_gp=10.0, post_method='softmax', batch_size=32, num_epochs=150, g_lr=0.0001, d_lr=0.0001, dropout=0.0, n_critic=5, resume_epoch=None, test_epochs=100, num_workers=1, mode='train', mol_data_dir='data/qm9_5k.sparsedataset', saving_dir='../exp_results/GAN/', log_step=1, sample_step=1000, model_save_step=1, lr_update_step=1000, lambda_wgan=0.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.saving_dir = os.path.join(config.saving_dir, get_date_postfix())\n",
    "config.log_dir_path = os.path.join(config.saving_dir, 'log_dir')\n",
    "config.model_dir_path = os.path.join(config.saving_dir, 'model_dir')\n",
    "config.img_dir_path = os.path.join(config.saving_dir, 'img_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if not exist.\n",
    "if not os.path.exists(config.log_dir_path):\n",
    "    os.makedirs(config.log_dir_path)\n",
    "if not os.path.exists(config.model_dir_path):\n",
    "    os.makedirs(config.model_dir_path)\n",
    "if not os.path.exists(config.img_dir_path):\n",
    "    os.makedirs(config.img_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_name = os.path.join(config.log_dir_path, get_date_postfix() + '_logger.log')\n",
    "logging.basicConfig(filename=log_p_name, level=logging.INFO)\n",
    "logging.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.mol_data_dir = '../data/qm9_5k.sparsedataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.sparse_molecular_dataset import SparseMolecularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = SparseMolecularDataset()\n",
    "data.load(config.mol_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Model configurations.\n",
    "z_dim = config.z_dim\n",
    "m_dim = data.atom_num_types\n",
    "b_dim = data.bond_num_types\n",
    "g_conv_dim = config.g_conv_dim\n",
    "d_conv_dim = config.d_conv_dim\n",
    "la = config.lambda_wgan\n",
    "lambda_rec = config.lambda_rec\n",
    "la_gp = config.lambda_gp\n",
    "post_method = config.post_method\n",
    "metric = 'validity,qed'\n",
    "# Training configurations.\n",
    "batch_size = config.batch_size\n",
    "num_epochs = config.num_epochs\n",
    "num_steps = (len(data) // batch_size)\n",
    "g_lr = config.g_lr\n",
    "d_lr = config.d_lr\n",
    "dropout = config.dropout\n",
    "if  la > 0:\n",
    "    n_critic = config.n_critic\n",
    "else:\n",
    "    n_critic = 1\n",
    "resume_epoch = config.resume_epoch\n",
    "# Training or testing.\n",
    "mode = config.mode\n",
    "\n",
    "# Miscellaneous.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: ', device)\n",
    "# Directories.\n",
    "log_dir_path = config.log_dir_path\n",
    "model_dir_path = config.model_dir_path\n",
    "img_dir_path = config.img_dir_path\n",
    "\n",
    "# Step size.\n",
    "model_save_step = config.model_save_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator network.\"\"\"\n",
    "\n",
    "    def __init__(self, conv_dims, z_dim, vertexes, edges, nodes, dropout_rate):\n",
    "        super(Generator, self).__init__()\n",
    "        self.activation_f = torch.nn.Tanh()\n",
    "        self.multi_dense_layer = MultiDenseLayer(z_dim, conv_dims, self.activation_f)\n",
    "\n",
    "        self.vertexes = vertexes\n",
    "        self.edges = edges\n",
    "        self.nodes = nodes\n",
    "\n",
    "        self.edges_layer = nn.Linear(conv_dims[-1], edges * vertexes * vertexes)\n",
    "        self.nodes_layer = nn.Linear(conv_dims[-1], vertexes * nodes)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.multi_dense_layer(x)\n",
    "        edges_logits = self.edges_layer(output).view(-1, self.edges, self.vertexes, self.vertexes)\n",
    "        edges_logits = (edges_logits + edges_logits.permute(0, 1, 3, 2)) / 2\n",
    "        edges_logits = self.dropout(edges_logits.permute(0, 2, 3, 1))\n",
    "\n",
    "        nodes_logits = self.nodes_layer(output)\n",
    "        nodes_logits = self.dropout(nodes_logits.view(-1, self.vertexes, self.nodes))\n",
    "\n",
    "        return edges_logits, nodes_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator network with PatchGAN.\"\"\"\n",
    "\n",
    "    def __init__(self, conv_dim, m_dim, b_dim, with_features=False, f_dim=0, dropout_rate=0.):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.activation_f = torch.nn.Tanh()\n",
    "        graph_conv_dim, aux_dim, linear_dim = conv_dim\n",
    "        # discriminator\n",
    "        self.gcn_layer = GraphConvolution(m_dim, graph_conv_dim, b_dim, with_features, f_dim, dropout_rate)\n",
    "        self.agg_layer = GraphAggregation(graph_conv_dim[-1] + m_dim, aux_dim, self.activation_f, with_features, f_dim,\n",
    "                                          dropout_rate)\n",
    "        self.multi_dense_layer = MultiDenseLayer(aux_dim, linear_dim, self.activation_f, dropout_rate=dropout_rate)\n",
    "\n",
    "        self.output_layer = nn.Linear(linear_dim[-1], 1)\n",
    "\n",
    "    def forward(self, adj, hidden, node, activation=None):\n",
    "        adj = adj[:, :, :, 1:].permute(0, 3, 1, 2)\n",
    "        h_1 = self.gcn_layer(node, adj, hidden)\n",
    "        h = self.agg_layer(h_1, node, hidden)\n",
    "        h = self.multi_dense_layer(h)\n",
    "\n",
    "        output = self.output_layer(h)\n",
    "        output = activation(output) if activation is not None else output\n",
    "\n",
    "        return output, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(g_conv_dim,\n",
    "          z_dim,\n",
    "          data.vertexes,\n",
    "          data.bond_num_types,\n",
    "          data.atom_num_types,\n",
    "          dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator(d_conv_dim, m_dim, b_dim - 1, dropout)\n",
    "V = Discriminator(d_conv_dim, m_dim, b_dim - 1, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_network(model, name, log=None):\n",
    "    \"\"\"Print out the network information.\"\"\"\n",
    "    num_params = 0\n",
    "    for p in model.parameters():\n",
    "        num_params += p.numel()\n",
    "    print(model)\n",
    "    print(name)\n",
    "    print(\"The number of parameters: {}\".format(num_params))\n",
    "    if log is not None:\n",
    "        log.info(model)\n",
    "        log.info(name)\n",
    "        log.info(\"The number of parameters: {}\".format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (activation_f): Tanh()\n",
      "  (multi_dense_layer): MultiDenseLayer(\n",
      "    (linear_layer): Sequential(\n",
      "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Tanh()\n",
      "      (3): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (4): Dropout(p=0.0, inplace=False)\n",
      "      (5): Tanh()\n",
      "      (6): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (7): Dropout(p=0.0, inplace=False)\n",
      "      (8): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (edges_layer): Linear(in_features=512, out_features=405, bias=True)\n",
      "  (nodes_layer): Linear(in_features=512, out_features=45, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "G\n",
      "The number of parameters: 396610\n",
      "Discriminator(\n",
      "  (activation_f): Tanh()\n",
      "  (gcn_layer): GraphConvolution(\n",
      "    (activation_f): Tanh()\n",
      "    (multi_graph_convolution_layers): MultiGraphConvolutionLayers(\n",
      "      (conv_nets): ModuleList(\n",
      "        (0): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (1): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (2): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (3): Linear(in_features=5, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=5, out_features=128, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (1): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (2): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (3): Linear(in_features=133, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=133, out_features=64, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (agg_layer): GraphAggregation(\n",
      "    (activation): Tanh()\n",
      "    (i): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (j): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (multi_dense_layer): MultiDenseLayer(\n",
      "    (linear_layer): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Tanh()\n",
      "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (4): Dropout(p=0.0, inplace=False)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "D\n",
      "The number of parameters: 89473\n",
      "Discriminator(\n",
      "  (activation_f): Tanh()\n",
      "  (gcn_layer): GraphConvolution(\n",
      "    (activation_f): Tanh()\n",
      "    (multi_graph_convolution_layers): MultiGraphConvolutionLayers(\n",
      "      (conv_nets): ModuleList(\n",
      "        (0): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (1): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (2): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (3): Linear(in_features=5, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=5, out_features=128, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): GraphConvolutionLayer(\n",
      "          (adj_list): ModuleList(\n",
      "            (0): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (1): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (2): Linear(in_features=133, out_features=64, bias=True)\n",
      "            (3): Linear(in_features=133, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear_2): Linear(in_features=133, out_features=64, bias=True)\n",
      "          (activation): Tanh()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (agg_layer): GraphAggregation(\n",
      "    (activation): Tanh()\n",
      "    (i): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (j): Sequential(\n",
      "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (multi_dense_layer): MultiDenseLayer(\n",
      "    (linear_layer): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): Dropout(p=0.0, inplace=False)\n",
      "      (2): Tanh()\n",
      "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (4): Dropout(p=0.0, inplace=False)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "V\n",
      "The number of parameters: 89473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (activation_f): Tanh()\n",
       "  (gcn_layer): GraphConvolution(\n",
       "    (activation_f): Tanh()\n",
       "    (multi_graph_convolution_layers): MultiGraphConvolutionLayers(\n",
       "      (conv_nets): ModuleList(\n",
       "        (0): GraphConvolutionLayer(\n",
       "          (adj_list): ModuleList(\n",
       "            (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=5, out_features=128, bias=True)\n",
       "            (3): Linear(in_features=5, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear_2): Linear(in_features=5, out_features=128, bias=True)\n",
       "          (activation): Tanh()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GraphConvolutionLayer(\n",
       "          (adj_list): ModuleList(\n",
       "            (0): Linear(in_features=133, out_features=64, bias=True)\n",
       "            (1): Linear(in_features=133, out_features=64, bias=True)\n",
       "            (2): Linear(in_features=133, out_features=64, bias=True)\n",
       "            (3): Linear(in_features=133, out_features=64, bias=True)\n",
       "          )\n",
       "          (linear_2): Linear(in_features=133, out_features=64, bias=True)\n",
       "          (activation): Tanh()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (agg_layer): GraphAggregation(\n",
       "    (activation): Tanh()\n",
       "    (i): Sequential(\n",
       "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "    (j): Sequential(\n",
       "      (0): Linear(in_features=69, out_features=128, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (multi_dense_layer): MultiDenseLayer(\n",
       "    (linear_layer): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): Dropout(p=0.0, inplace=False)\n",
       "      (2): Tanh()\n",
       "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (4): Dropout(p=0.0, inplace=False)\n",
       "      (5): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_optimizer = torch.optim.RMSprop(G.parameters(), g_lr)\n",
    "d_optimizer = torch.optim.RMSprop(D.parameters(), d_lr)\n",
    "v_optimizer = torch.optim.RMSprop(V.parameters(), g_lr)\n",
    "print_network(G, 'G', logging)\n",
    "print_network(D, 'D', logging)\n",
    "print_network(V, 'V', logging)\n",
    "\n",
    "G.to(device)\n",
    "D.to(device)\n",
    "V.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_la = la\n",
    "epoch_i = 0\n",
    "a_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "losses = defaultdict(list)\n",
    "scores = defaultdict(list)\n",
    "the_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, smiles, data_S, data_A, data_X, data_D, data_F, data_Le, data_Lv\n",
    "# a: Adjacent matrix,\n",
    "# x: node \n",
    "mols, _, _, a, x, _, _, _, _ = data.next_train_batch(batch_size) # generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate single data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### molecular graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7f07bf8b8450>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mols[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### molecular graph with detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x7f07bf8b8450>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, atom in enumerate(mols[1].GetAtoms()):\n",
    "    atom.SetProp('molAtomMapNumber', str(atom.GetIdx()))\n",
    "mols[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### how to make adjacent matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = None\n",
    "max_length = max_length if max_length is not None else mols[1].GetNumAtoms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 6, 8]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b.GetBeginAtomIdx() for b in mols[1].GetBonds()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 1, 6]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b.GetEndAtomIdx() for b in mols[1].GetBonds()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get directed graph\n",
    "begin, end = [b.GetBeginAtomIdx() for b in mols[1].GetBonds()], [b.GetEndAtomIdx() for b in mols[1].GetBonds()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros(shape=(max_length, max_length), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Bond Type\n",
    "* 모든 bond type을 다가져와야 하나 여기서는 32개의 sample에 대한 bond type만 가지고 와서 bond_encoder_m이라는 index set을 만들고\n",
    "* 실제 bond type을 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "bond_labels = [Chem.rdchem.BondType.ZERO] + list(sorted(set(bond.GetBondType()\n",
    "                                                            for mol in mols\n",
    "                                                            for bond in mol.GetBonds())))\n",
    "bond_encoder_m = {l: i for i, l in enumerate(bond_labels)}\n",
    "bond_type = [bond_encoder_m[b.GetBondType()] for b in mols[1].GetBonds()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 2, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bond_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make adjacent matrix\n",
    "# Position: connection, Value: bond type\n",
    "A[begin, end] = bond_type\n",
    "A[end, begin] = bond_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 2, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 2, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = np.sum(A[:mols[1].GetNumAtoms(), :mols[1].GetNumAtoms()], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to make node tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_labels = sorted(set([atom.GetAtomicNum() for mol in mols for atom in mol.GetAtoms()] + [0]))\n",
    "atom_encoder_m = {l: i for i, l in enumerate(atom_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 6: 1, 7: 2, 8: 3, 9: 4}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_encoder_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = np.array([\n",
    "        atom_encoder_m[atom.GetAtomicNum()] \n",
    "        for atom in mols[1].GetAtoms()\n",
    "        ] + [0] * ( max_length - mols[1].GetNumAtoms() ), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 1, 1, 1, 1, 1, 1, 2], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2onehot(labels, dim):\n",
    "    \"\"\"Convert label indices to one-hot vectors.\"\"\"\n",
    "    out = torch.zeros(list(labels.size()) + [dim]).to(device)\n",
    "    out.scatter_(len(out.size()) - 1, labels.unsqueeze(-1), 1.)\n",
    "    return out\n",
    "\n",
    "def sample_z(batch_size):\n",
    "    return np.random.normal(0, 1, size=(batch_size, z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = sample_z(a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미 GPU에 올라가 있으면 아래 코드 중 첫 두줄은 필요 없음\n",
    "a = torch.from_numpy(a).to(device).long()  # Adjacency.\n",
    "x = torch.from_numpy(x).to(device).long()  # Nodes.\n",
    "a_tensor = label2onehot(a, b_dim)\n",
    "x_tensor = label2onehot(x, m_dim)\n",
    "z = torch.from_numpy(z).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_step = num_steps * epoch_i + a_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_tensor: Adjacent matrix\n",
    "# x_tensor: node\n",
    "logits_real, features_real = D(a_tensor, None, x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_logits, nodes_logits = G(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0774,  0.0450, -0.0865, -0.3240,  0.0169],\n",
       "        [-0.0176,  0.0249, -0.1331,  0.0436,  0.0210],\n",
       "        [-0.0113, -0.0975, -0.0461, -0.0442,  0.1225],\n",
       "        [ 0.0660, -0.2631,  0.1256, -0.0183, -0.1172],\n",
       "        [ 0.1073,  0.0654, -0.0848,  0.0100,  0.0300],\n",
       "        [ 0.0533,  0.1114, -0.0621,  0.0798,  0.0966],\n",
       "        [-0.1837, -0.0432, -0.0291,  0.0112, -0.3214],\n",
       "        [ 0.1604,  0.0431, -0.0435,  0.0617,  0.0324],\n",
       "        [ 0.1529, -0.0191,  0.0448, -0.0465,  0.0156]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(inputs, method, temperature=1.):\n",
    "    def listify(x):\n",
    "        return x if type(x) == list or type(x) == tuple else [x]\n",
    "\n",
    "    def delistify(x):\n",
    "        return x if len(x) > 1 else x[0]\n",
    "\n",
    "    if method == 'soft_gumbel':\n",
    "        softmax = [F.gumbel_softmax(e_logits.contiguous().view(-1, e_logits.size(-1))\n",
    "                                    / temperature, hard=False).view(e_logits.size())\n",
    "                   for e_logits in listify(inputs)]\n",
    "    elif method == 'hard_gumbel':\n",
    "        softmax = [F.gumbel_softmax(e_logits.contiguous().view(-1, e_logits.size(-1))\n",
    "                                    / temperature, hard=True).view(e_logits.size())\n",
    "                   for e_logits in listify(inputs)]\n",
    "    else:\n",
    "        softmax = [F.softmax(e_logits / temperature, -1)\n",
    "                   for e_logits in listify(inputs)]\n",
    "\n",
    "    return [delistify(e) for e in (softmax)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'softmax'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "(edges_hat, nodes_hat) = postprocess((edges_logits, nodes_logits), post_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 9, 9, 5])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1680, 0.2149, 0.1913, 0.2136, 0.2081, 0.2233, 0.1932, 0.1735, 0.1838],\n",
       "        [0.2149, 0.1891, 0.2028, 0.1787, 0.1946, 0.1935, 0.1935, 0.1940, 0.2035],\n",
       "        [0.1913, 0.2028, 0.2032, 0.1863, 0.1934, 0.2073, 0.1986, 0.2070, 0.1946],\n",
       "        [0.2136, 0.1787, 0.1863, 0.2422, 0.2080, 0.1741, 0.2169, 0.2017, 0.2053],\n",
       "        [0.2081, 0.1946, 0.1934, 0.2080, 0.2183, 0.1915, 0.2189, 0.1927, 0.1963],\n",
       "        [0.2233, 0.1935, 0.2073, 0.1741, 0.1915, 0.1698, 0.1916, 0.1948, 0.1881],\n",
       "        [0.1932, 0.1935, 0.1986, 0.2169, 0.2189, 0.1916, 0.2145, 0.1821, 0.1999],\n",
       "        [0.1735, 0.1940, 0.2070, 0.2017, 0.1927, 0.1948, 0.1821, 0.1894, 0.2023],\n",
       "        [0.1838, 0.2035, 0.1946, 0.2053, 0.1963, 0.1881, 0.1999, 0.2023, 0.2144]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_hat[1, :, :, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_fake, features_fake = D(edges_hat, None, nodes_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(y, x):\n",
    "    \"\"\"Compute gradient penalty: (L2_norm(dy/dx) - 1)**2.\"\"\"\n",
    "    weight = torch.ones(y.size()).to(device)\n",
    "    dydx = torch.autograd.grad(outputs=y,\n",
    "                               inputs=x,\n",
    "                               grad_outputs=weight,\n",
    "                               retain_graph=True,\n",
    "                               create_graph=True,\n",
    "                               only_inputs=True)[0]\n",
    "    dydx = dydx.view(dydx.size(0), -1)\n",
    "    dydx_l2norm = torch.sqrt(torch.sum(dydx ** 2, dim=1))\n",
    "    return torch.mean((dydx_l2norm - 1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute losses for gradient penalty.\n",
    "eps = torch.rand(logits_real.size(0), 1, 1, 1).to(device)\n",
    "x_int0 = (eps * a_tensor + (1. - eps) * edges_hat).requires_grad_(True)\n",
    "x_int1 = (eps.squeeze(-1) * x_tensor + (1. - eps.squeeze(-1)) * nodes_hat).requires_grad_(True)\n",
    "grad0, grad1 = D(x_int0, None, x_int1)\n",
    "grad_penalty = gradient_penalty(grad0, x_int0) + gradient_penalty(grad1, x_int1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_real = torch.mean(logits_real)\n",
    "d_loss_fake = torch.mean(logits_fake)\n",
    "loss_D = - d_loss_real + d_loss_fake + la_gp * grad_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses['l_D/R'].append(d_loss_real.item())\n",
    "losses['l_D/F'].append(d_loss_fake.item())\n",
    "losses['l_D'].append(loss_D.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'l_D/R': [0.30454879999160767],\n",
       "             'l_D/F': [0.0014736459124833345],\n",
       "             'l_D': [7.486253261566162]})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    \"\"\"Reset the gradient buffers.\"\"\"\n",
    "    g_optimizer.zero_grad()\n",
    "    d_optimizer.zero_grad()\n",
    "    v_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_grad()\n",
    "loss_D.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_optimizer.state_dict()['state'][0]['square_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'validity,qed'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(mols):\n",
    "    rr = 1.\n",
    "    for m in ('logp,sas,qed,unique' if metric == 'all' else metric).split(','):\n",
    "        if m == 'np':\n",
    "            rr *= MolecularMetrics.natural_product_scores(mols, norm=True)\n",
    "        elif m == 'logp':\n",
    "            rr *= MolecularMetrics.water_octanol_partition_coefficient_scores(mols, norm=True)\n",
    "        elif m == 'sas':\n",
    "            rr *= MolecularMetrics.synthetic_accessibility_score_scores(mols, norm=True)\n",
    "        elif m == 'qed':\n",
    "            rr *= MolecularMetrics.quantitative_estimation_druglikeness_scores(mols, norm=True)\n",
    "        elif m == 'novelty':\n",
    "            rr *= MolecularMetrics.novel_scores(mols, data)\n",
    "        elif m == 'dc':\n",
    "            rr *= MolecularMetrics.drugcandidate_scores(mols, data)\n",
    "        elif m == 'unique':\n",
    "            rr *= MolecularMetrics.unique_scores(mols)\n",
    "        elif m == 'diversity':\n",
    "            rr *= MolecularMetrics.diversity_scores(mols, data)\n",
    "        elif m == 'validity':\n",
    "            rr *= MolecularMetrics.valid_scores(mols)\n",
    "        else:\n",
    "            raise RuntimeError('{} is not defined as a metric'.format(m))\n",
    "    return rr.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(n_hat, e_hat, method):\n",
    "    (edges_hard, nodes_hard) = postprocess((e_hat, n_hat), method)\n",
    "    edges_hard, nodes_hard = torch.max(edges_hard, -1)[1], torch.max(nodes_hard, -1)[1]\n",
    "    mols = [data.matrices2mol(n_.data.cpu().numpy(), e_.data.cpu().numpy(), strict=True)\n",
    "            for e_, n_ in zip(edges_hard, nodes_hard)]\n",
    "    _reward = torch.from_numpy(reward(mols)).to(device)\n",
    "    return _reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-to-target\n",
    "edges_logits, nodes_logits = G(z)\n",
    "# Postprocess with Gumbel softmax\n",
    "(edges_hat, nodes_hat) = postprocess((edges_logits, nodes_logits), post_method)\n",
    "logits_fake, features_fake = D(edges_hat, None, nodes_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value losses\n",
    "value_logit_real, _ = V(a_tensor, None, x_tensor, torch.sigmoid)\n",
    "value_logit_fake, _ = V(edges_hat, None, nodes_hat, torch.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MolecularMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature mapping losses. Not used anywhere in the PyTorch version.\n",
    "# I include it here for the consistency with the TF code.\n",
    "f_loss = (torch.mean(features_real, 0) - torch.mean(features_fake, 0)) ** 2\n",
    "\n",
    "# Real Reward\n",
    "reward_r = torch.from_numpy(reward(mols)).to(device)\n",
    "# Fake Reward\n",
    "reward_f = get_reward(nodes_hat, edges_hat, post_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses Update\n",
    "loss_G = -logits_fake\n",
    "# Original TF loss_V. Here we use absolute values instead of the squared one.\n",
    "# loss_V = (value_logit_real - reward_r) ** 2 + (value_logit_fake - reward_f) ** 2\n",
    "loss_V = torch.abs(value_logit_real - reward_r) + torch.abs(value_logit_fake - reward_f)\n",
    "loss_RL = -value_logit_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_RL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_G = torch.mean(loss_G)\n",
    "loss_V = torch.mean(loss_V)\n",
    "loss_RL = torch.mean(loss_RL)\n",
    "losses['l_G'].append(loss_G.item())\n",
    "losses['l_RL'].append(loss_RL.item())\n",
    "losses['l_V'].append(loss_V.item())\n",
    "alpha = torch.abs(loss_G.detach() / loss_RL.detach()).detach()\n",
    "train_step_G = cur_la * loss_G + (1 - cur_la) * alpha * loss_RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyle/.pyenv/versions/3.9.2/envs/molgan/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: Error detected in AddmmBackward0. No forward pass information available. Enable detect anomaly during forward pass for more information. (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:92.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [512, 45]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Optimise value network.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mif\u001b[39;00m cur_step \u001b[39m%\u001b[39m n_critic \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 13\u001b[0m     train_step_V\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m) \u001b[39m## 여기에서 에러가 난다.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     v_optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/envs/molgan/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/envs/molgan/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [512, 45]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True) \n",
    "\n",
    "alpha = torch.abs(loss_G.detach() / loss_RL.detach()).detach()\n",
    "train_step_G = cur_la * loss_G + (1 - cur_la) * alpha * loss_RL\n",
    "train_step_V = loss_V\n",
    "reset_grad()\n",
    "# Optimise generator.\n",
    "if cur_step % n_critic == 0:\n",
    "    train_step_G.backward(retain_graph=True)\n",
    "    g_optimizer.step()\n",
    "# Optimise value network.\n",
    "if cur_step % n_critic == 0:\n",
    "    train_step_V.backward() ## 여기에서 에러가 난다.\n",
    "    v_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # =================================================================================== #\n",
    "            #                               3. Train the generator                                #\n",
    "            # =================================================================================== #\n",
    "\n",
    "            # Z-to-target\n",
    "            edges_logits, nodes_logits = self.G(z)\n",
    "            # Postprocess with Gumbel softmax\n",
    "            (edges_hat, nodes_hat) = self.postprocess((edges_logits, nodes_logits), self.post_method)\n",
    "            logits_fake, features_fake = self.D(edges_hat, None, nodes_hat)\n",
    "\n",
    "            # Value losses\n",
    "            value_logit_real, _ = self.V(a_tensor, None, x_tensor, torch.sigmoid)\n",
    "            value_logit_fake, _ = self.V(edges_hat, None, nodes_hat, torch.sigmoid)\n",
    "\n",
    "            # Feature mapping losses. Not used anywhere in the PyTorch version.\n",
    "            # I include it here for the consistency with the TF code.\n",
    "            f_loss = (torch.mean(features_real, 0) - torch.mean(features_fake, 0)) ** 2\n",
    "\n",
    "            # Real Reward\n",
    "            reward_r = torch.from_numpy(self.reward(mols)).to(self.device)\n",
    "            # Fake Reward\n",
    "            reward_f = self.get_reward(nodes_hat, edges_hat, self.post_method)\n",
    "\n",
    "            # Losses Update\n",
    "            loss_G = -logits_fake\n",
    "            # Original TF loss_V. Here we use absolute values instead of the squared one.\n",
    "            # loss_V = (value_logit_real - reward_r) ** 2 + (value_logit_fake - reward_f) ** 2\n",
    "            loss_V = torch.abs(value_logit_real - reward_r) + torch.abs(value_logit_fake - reward_f)\n",
    "            loss_RL = -value_logit_fake\n",
    "\n",
    "            loss_G = torch.mean(loss_G)\n",
    "            loss_V = torch.mean(loss_V)\n",
    "            loss_RL = torch.mean(loss_RL)\n",
    "            losses['l_G'].append(loss_G.item())\n",
    "            losses['l_RL'].append(loss_RL.item())\n",
    "            losses['l_V'].append(loss_V.item())\n",
    "\n",
    "            alpha = torch.abs(loss_G.detach() / loss_RL.detach()).detach()\n",
    "            train_step_G = cur_la * loss_G + (1 - cur_la) * alpha * loss_RL\n",
    "\n",
    "            train_step_V = loss_V\n",
    "\n",
    "            if train_val_test == 'train':\n",
    "                self.reset_grad()\n",
    "\n",
    "                # Optimise generator.\n",
    "                if cur_step % self.n_critic == 0:\n",
    "                    train_step_G.backward(retain_graph=True)\n",
    "                    self.g_optimizer.step()\n",
    "\n",
    "                # Optimise value network.\n",
    "                if cur_step % self.n_critic == 0:\n",
    "                    train_step_V.backward()\n",
    "                    self.v_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "for i in range(start_epoch, num_epochs):\n",
    "    self.train_or_valid(epoch_i=i, train_val_test='train')\n",
    "    self.train_or_valid(epoch_i=i, train_val_test='val')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MolGan",
   "language": "python",
   "name": "molgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2021aad42aed9ec2de6443e4c206b312b12517efbcc0ff7ef55ad01c65ceb8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
